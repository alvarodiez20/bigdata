{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 02: Complexity and the Data Flow\n",
                "\n",
                "**Course:** Big Data\n",
                "\n",
                "---\n",
                "\n",
                "## üë§ Student Information\n",
                "\n",
                "**Name:** `Your Name Here`\n",
                "\n",
                "**Date:** `DD/MM/YYYY`\n",
                "\n",
                "---\n",
                "\n",
                "**Goal:** Understand computational complexity at scale and optimize data processing patterns.\n",
                "\n",
                "## Learning Objectives\n",
                "\n",
                "By the end of this lab, you will be able to:\n",
                "\n",
                "1. **Experience The Scale Factor**: Feel the difference between N=1,000 and N=1,000,000\n",
                "2. **Prove Memory Hierarchy Impact**: Demonstrate that RAM is faster than Disk\n",
                "3. **Apply Big O in Practice**: Transition from O(N¬≤) to O(N log N) or O(N)\n",
                "4. **Use Profiling Tools**: Identify bottlenecks with `timeit` and `cProfile`\n",
                "\n",
                "## Instructions\n",
                "\n",
                "1. **Fill in your information above** before starting the lab\n",
                "2. Read each cell carefully before running it\n",
                "3. Implement the **TODO functions** when you see them\n",
                "4. Run cells **from top to bottom** (Shift+Enter)\n",
                "5. Check that output makes sense after each cell\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìö Libraries Used in This Lab\n",
                "\n",
                "### Core Libraries\n",
                "\n",
                "- **`pandas`** - Data manipulation (CSV/Parquet reading, chunking)\n",
                "- **`numpy`** - Random data generation and statistics\n",
                "- **`time`** - Performance timing with `perf_counter()`\n",
                "- **`cProfile`** - Python's built-in profiler for identifying bottlenecks\n",
                "- **`collections`** - High-performance container datatypes (`Counter`)\n",
                "- **`psutil`** - Memory usage monitoring\n",
                "\n",
                "### Why These Libraries?\n",
                "\n",
                "- **cProfile**: Shows you exactly WHERE your code spends time\n",
                "- **collections.Counter**: O(N) duplicate detection vs O(N¬≤) naive loops\n",
                "- **psutil**: Real memory measurements to prove RAM vs Disk differences\n",
                "\n",
                "---\n",
                "\n",
                "## üí° The Red Zone: Working at Scale\n",
                "\n",
                "In this lab, we work with **1,000,000 rows** ‚Äî the \"Red Zone\" where:\n",
                "\n",
                "- O(N¬≤) algorithms become **painfully slow** (1 trillion operations!)\n",
                "- O(N) algorithms remain **fast** (only 1 million operations)\n",
                "- Memory management becomes **critical**\n",
                "\n",
                "This is where Big Data thinking starts!\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import time\n",
                "import cProfile\n",
                "import pstats\n",
                "import io\n",
                "from pathlib import Path\n",
                "from collections import Counter\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import psutil\n",
                "\n",
                "print(\"‚úì All imports successful!\")\n",
                "print(f\"Pandas version: {pd.__version__}\")\n",
                "print(f\"NumPy version: {np.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Base directories\n",
                "DATA_RAW = Path(\"../data/raw\")\n",
                "RESULTS_DIR = Path(\"../results\")\n",
                "\n",
                "# File paths for this lab\n",
                "USER_LOGS_PATH = DATA_RAW / \"user_logs_1m.csv\"\n",
                "METRICS_PATH = RESULTS_DIR / \"lab02_metrics.json\"\n",
                "\n",
                "# Ensure directories exist\n",
                "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
                "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "print(\"Paths defined:\")\n",
                "print(f\"  User Logs: {USER_LOGS_PATH}\")\n",
                "print(f\"  Metrics: {METRICS_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 3. Dataset Generation: Enter the Red Zone üî¥\n",
                "\n",
                "First, we need to generate a **1 million row** synthetic dataset.\n",
                "\n",
                "This dataset simulates user activity logs with:\n",
                "- `user_id`: Random user IDs (1 to 50,000) ‚Äî some users appear multiple times!\n",
                "- `session_id`: Unique session identifier\n",
                "- `action`: Random action type (\"click\", \"view\", \"purchase\", \"scroll\", \"search\")\n",
                "- `timestamp`: Sequential timestamps\n",
                "- `value`: Random numeric value (e.g., time spent, amount)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TODO 1: `generate_user_logs()`\n",
                "\n",
                "Generate a synthetic dataset with 1 million rows.\n",
                "\n",
                "**üí° Hints:**\n",
                "- Use `np.random.seed(seed)` for reproducibility\n",
                "- Use `np.random.randint(1, 50001, size=n_rows)` for user_ids (creates duplicates!)\n",
                "- Use `np.arange(n_rows)` for session_ids (unique)\n",
                "- Use `np.random.choice([...], size=n_rows)` for actions\n",
                "- Use `pd.date_range()` for timestamps\n",
                "- Save with `df.to_csv(path, index=False)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_user_logs(path: Path, n_rows: int = 1_000_000, seed: int = 42) -> dict:\n",
                "    \"\"\"\n",
                "    Generate a synthetic user logs dataset.\n",
                "    \n",
                "    Args:\n",
                "        path: Where to save the CSV\n",
                "        n_rows: Number of rows (default 1 million)\n",
                "        seed: Random seed for reproducibility\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary with: {\"rows\": int, \"cols\": int, \"size_mb\": float}\n",
                "    \"\"\"\n",
                "    # TODO: Implement this function\n",
                "    # Step 1: Set random seed\n",
                "    # Step 2: Generate user_id (1 to 50000, allows duplicates)\n",
                "    # Step 3: Generate session_id (0 to n_rows-1, unique)\n",
                "    # Step 4: Generate action (random choice from list)\n",
                "    # Step 5: Generate timestamp (date_range)\n",
                "    # Step 6: Generate value (random float 0-1000)\n",
                "    # Step 7: Create DataFrame\n",
                "    # Step 8: Save to CSV\n",
                "    # Step 9: Return metadata\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Generate the dataset (only if it doesn't exist)\n",
                "if not USER_LOGS_PATH.exists():\n",
                "    print(\"üî¥ Entering the Red Zone: Generating 1 million rows...\")\n",
                "    start = time.perf_counter()\n",
                "    metadata = generate_user_logs(USER_LOGS_PATH)\n",
                "    elapsed = time.perf_counter() - start\n",
                "    print(f\"Generated in {elapsed:.2f} seconds\")\n",
                "    print(f\"Dataset: {metadata}\")\n",
                "    assert metadata[\"rows\"] == 1_000_000, \"Should have 1M rows\"\n",
                "    print(\"‚úì generate_user_logs() works correctly!\")\n",
                "else:\n",
                "    size_mb = USER_LOGS_PATH.stat().st_size / 1_000_000\n",
                "    print(f\"Dataset already exists: {size_mb:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Exercise 1: Search Efficiency ‚Äî O(N) vs O(1) üîç\n",
                "\n",
                "**The Question**: How fast can we check if a value exists in a collection?\n",
                "\n",
                "We'll compare:\n",
                "- **List**: `x in my_list` ‚Üí O(N) ‚Äî must scan every element\n",
                "- **Set**: `x in my_set` ‚Üí O(1) ‚Äî hash lookup, instant!\n",
                "\n",
                "At N=1,000,000, this difference is **dramatic**."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TODO 2: `benchmark_search()`\n",
                "\n",
                "Compare search performance in a List vs a Set.\n",
                "\n",
                "**üí° Hints:**\n",
                "- Create both a list and set with the same data: `list(range(n))`\n",
                "- Search for random keys using `np.random.randint()`\n",
                "- Use `time.perf_counter()` to measure each search\n",
                "- Return the median time for each structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def benchmark_search(n: int = 1_000_000, n_searches: int = 1000, seed: int = 42) -> dict:\n",
                "    \"\"\"\n",
                "    Benchmark search performance: List vs Set.\n",
                "    \n",
                "    Args:\n",
                "        n: Size of the collection\n",
                "        n_searches: Number of searches to perform\n",
                "        seed: Random seed\n",
                "    \n",
                "    Returns:\n",
                "        Dictionary with:\n",
                "            - \"list_median_ms\": median search time in List (milliseconds)\n",
                "            - \"set_median_ms\": median search time in Set (milliseconds)\n",
                "            - \"speedup\": how many times faster Set is\n",
                "    \"\"\"\n",
                "    # TODO: Implement this function\n",
                "    # Step 1: Create list and set with range(n)\n",
                "    # Step 2: Generate random keys to search for\n",
                "    # Step 3: Time each search in the list, collect times\n",
                "    # Step 4: Time each search in the set, collect times\n",
                "    # Step 5: Calculate medians and speedup\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Benchmark search\n",
                "print(\"Benchmarking List vs Set search (1M elements, 1000 searches)...\")\n",
                "print(\"This may take a moment...\\n\")\n",
                "\n",
                "search_results = benchmark_search(n=1_000_000, n_searches=1000)\n",
                "\n",
                "print(f\"List median search time: {search_results['list_median_ms']:.4f} ms\")\n",
                "print(f\"Set median search time:  {search_results['set_median_ms']:.6f} ms\")\n",
                "print(f\"\\nüöÄ Set is {search_results['speedup']:.0f}x faster!\")\n",
                "\n",
                "assert search_results[\"speedup\"] > 100, \"Set should be at least 100x faster\"\n",
                "print(\"\\n‚úì benchmark_search() works correctly!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üí° Key Insight: Hash Tables\n",
                "\n",
                "Sets and Dictionaries use **hash tables** for O(1) lookup:\n",
                "\n",
                "| Structure | Lookup | Memory | Use Case |\n",
                "|-----------|--------|--------|----------|\n",
                "| List | O(N) | Low | Ordered data, iteration |\n",
                "| Set | O(1) | Higher | Membership testing |\n",
                "| Dict | O(1) | Highest | Key-value mapping |\n",
                "\n",
                "**Rule of thumb**: If you're checking `x in collection` repeatedly, use a Set!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Exercise 2: The Data Flow ‚Äî Memory Hierarchy üìä\n",
                "\n",
                "**The Memory Pyramid**:\n",
                "```\n",
                "       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "       ‚îÇ  L1/L2  ‚îÇ  ‚Üê Fastest (nanoseconds)\n",
                "       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "       ‚îÇ   RAM   ‚îÇ  ‚Üê Fast (microseconds)\n",
                "       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "       ‚îÇ   SSD   ‚îÇ  ‚Üê Slower (milliseconds)\n",
                "       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "       ‚îÇ   HDD   ‚îÇ  ‚Üê Slowest (milliseconds)\n",
                "       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```\n",
                "\n",
                "We'll prove this by comparing three ways to process our 1M row CSV:\n",
                "\n",
                "1. **Full Load**: Load entire file into RAM\n",
                "2. **Chunking**: Load in chunks (controlled memory)\n",
                "3. **Line Iterator**: Read line by line (minimal memory)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TODO 3: `load_full()`, `load_chunked()`, `load_iterator()`\n",
                "\n",
                "Implement three different loading strategies.\n",
                "\n",
                "**üí° Hints:**\n",
                "- `pd.read_csv(path)` for full load\n",
                "- `pd.read_csv(path, chunksize=N)` for chunking (returns iterator)\n",
                "- `open(path)` and `for line in f:` for line iterator\n",
                "- Use `psutil.Process().memory_info().rss` to measure memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_memory_mb() -> float:\n",
                "    \"\"\"Get current process memory usage in MB.\"\"\"\n",
                "    return psutil.Process().memory_info().rss / 1_000_000\n",
                "\n",
                "\n",
                "def load_full(path: Path) -> dict:\n",
                "    \"\"\"\n",
                "    Load entire CSV into memory.\n",
                "    \n",
                "    Returns:\n",
                "        {\"rows\": int, \"time_sec\": float, \"memory_mb\": float}\n",
                "    \"\"\"\n",
                "    # TODO: Implement\n",
                "    # 1. Record start memory and time\n",
                "    # 2. Load with pd.read_csv()\n",
                "    # 3. Record end memory and time\n",
                "    # 4. Return metrics\n",
                "    pass\n",
                "\n",
                "\n",
                "def load_chunked(path: Path, chunksize: int = 50_000) -> dict:\n",
                "    \"\"\"\n",
                "    Load CSV in chunks and process.\n",
                "    \n",
                "    Returns:\n",
                "        {\"rows\": int, \"time_sec\": float, \"peak_memory_mb\": float}\n",
                "    \"\"\"\n",
                "    # TODO: Implement\n",
                "    # 1. Record start time\n",
                "    # 2. Iterate through chunks: for chunk in pd.read_csv(path, chunksize=chunksize)\n",
                "    # 3. Count rows, track peak memory\n",
                "    # 4. Return metrics\n",
                "    pass\n",
                "\n",
                "\n",
                "def load_iterator(path: Path) -> dict:\n",
                "    \"\"\"\n",
                "    Load CSV line by line (minimal memory).\n",
                "    \n",
                "    Returns:\n",
                "        {\"rows\": int, \"time_sec\": float, \"memory_mb\": float}\n",
                "    \"\"\"\n",
                "    # TODO: Implement\n",
                "    # 1. Record start time\n",
                "    # 2. Open file and count lines (skip header)\n",
                "    # 3. Record end time and memory\n",
                "    # 4. Return metrics\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Compare loading strategies\n",
                "print(\"Comparing data loading strategies...\\n\")\n",
                "\n",
                "print(\"1. Full Load (all into RAM)...\")\n",
                "full_result = load_full(USER_LOGS_PATH)\n",
                "print(f\"   Rows: {full_result['rows']:,}\")\n",
                "print(f\"   Time: {full_result['time_sec']:.3f} sec\")\n",
                "print(f\"   Memory: {full_result['memory_mb']:.1f} MB\\n\")\n",
                "\n",
                "print(\"2. Chunked Load (50k at a time)...\")\n",
                "chunked_result = load_chunked(USER_LOGS_PATH)\n",
                "print(f\"   Rows: {chunked_result['rows']:,}\")\n",
                "print(f\"   Time: {chunked_result['time_sec']:.3f} sec\")\n",
                "print(f\"   Peak Memory: {chunked_result['peak_memory_mb']:.1f} MB\\n\")\n",
                "\n",
                "print(\"3. Line Iterator (minimal memory)...\")\n",
                "iterator_result = load_iterator(USER_LOGS_PATH)\n",
                "print(f\"   Rows: {iterator_result['rows']:,}\")\n",
                "print(f\"   Time: {iterator_result['time_sec']:.3f} sec\")\n",
                "print(f\"   Memory: {iterator_result['memory_mb']:.1f} MB\\n\")\n",
                "\n",
                "print(\"‚úì Data flow comparison complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üí° Key Insight: Trade-offs\n",
                "\n",
                "| Method | Speed | Memory | Use Case |\n",
                "|--------|-------|--------|----------|\n",
                "| Full Load | Fastest | Highest | Data fits in RAM, need random access |\n",
                "| Chunking | Medium | Controlled | Large files, aggregate operations |\n",
                "| Iterator | Slowest | Minimal | Huge files, streaming processing |\n",
                "\n",
                "**Rule**: Always know your data size relative to available RAM!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Exercise 3: Identifying the Bottleneck üî•\n",
                "\n",
                "**The Problem**: You have a slow function. Where is the time going?\n",
                "\n",
                "We'll use **profiling** to find the \"hot\" lines of code.\n",
                "\n",
                "Here's a deliberately **bad** function that finds duplicate user_ids:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_duplicates_slow(data: list) -> list:\n",
                "    \"\"\"\n",
                "    Find duplicate values in a list.\n",
                "    \n",
                "    WARNING: This is O(N¬≤) ‚Äî VERY SLOW for large data!\n",
                "    \n",
                "    Args:\n",
                "        data: List of values to check\n",
                "    \n",
                "    Returns:\n",
                "        List of duplicate values\n",
                "    \"\"\"\n",
                "    duplicates = []\n",
                "    for i in range(len(data)):\n",
                "        for j in range(i + 1, len(data)):\n",
                "            if data[i] == data[j] and data[i] not in duplicates:\n",
                "                duplicates.append(data[i])\n",
                "    return duplicates\n",
                "\n",
                "\n",
                "print(\"Slow function defined. Let's profile it!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TODO 4: Profile the slow function\n",
                "\n",
                "Use `cProfile` to identify where the function spends time.\n",
                "\n",
                "**üí° Hints:**\n",
                "- Use `cProfile.Profile()` to create a profiler\n",
                "- Use `profiler.enable()` and `profiler.disable()` to wrap the function call\n",
                "- Use `pstats.Stats(profiler)` to analyze results\n",
                "- Sort by `'cumulative'` time to see the biggest bottlenecks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def profile_function(fn, *args, **kwargs) -> tuple:\n",
                "    \"\"\"\n",
                "    Profile a function and return timing info.\n",
                "    \n",
                "    Args:\n",
                "        fn: Function to profile\n",
                "        *args, **kwargs: Arguments to pass to the function\n",
                "    \n",
                "    Returns:\n",
                "        Tuple of (result, stats_string, total_time)\n",
                "    \"\"\"\n",
                "    # TODO: Implement profiling\n",
                "    # 1. Create profiler: pr = cProfile.Profile()\n",
                "    # 2. Enable profiler: pr.enable()\n",
                "    # 3. Call the function: result = fn(*args, **kwargs)\n",
                "    # 4. Disable profiler: pr.disable()\n",
                "    # 5. Create stats: stats = pstats.Stats(pr)\n",
                "    # 6. Sort by cumulative time: stats.sort_stats('cumulative')\n",
                "    # 7. Capture stats to string using io.StringIO()\n",
                "    # 8. Return result, stats string, and total time\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Profile the slow function with a SMALL sample\n",
                "# Using 10,000 items (not 1M!) because O(N¬≤) = 100 million operations\n",
                "print(\"Loading sample data for profiling...\")\n",
                "sample_df = pd.read_csv(USER_LOGS_PATH, nrows=10_000)\n",
                "sample_users = sample_df['user_id'].tolist()\n",
                "print(f\"Sample size: {len(sample_users):,} users\\n\")\n",
                "\n",
                "print(\"Profiling find_duplicates_slow()...\")\n",
                "print(\"(This will take 10-30 seconds due to O(N¬≤) complexity)\\n\")\n",
                "\n",
                "result, stats_string, total_time = profile_function(find_duplicates_slow, sample_users)\n",
                "\n",
                "print(f\"Found {len(result)} duplicate user_ids\")\n",
                "print(f\"Total time: {total_time:.2f} seconds\\n\")\n",
                "print(\"Profile output (top 10 lines):\")\n",
                "print(stats_string)\n",
                "\n",
                "print(\"\\n‚úì Profiling complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### üí° Reading the Profile Output\n",
                "\n",
                "The profile shows:\n",
                "- **ncalls**: Number of times the function was called\n",
                "- **tottime**: Time spent IN the function (excluding sub-calls)\n",
                "- **cumtime**: Total time INCLUDING sub-calls\n",
                "\n",
                "**The bottleneck**: The nested loops (`for i... for j...`) create O(N¬≤) comparisons!\n",
                "\n",
                "For N=10,000: N¬≤ = 100,000,000 comparisons\n",
                "For N=1,000,000: N¬≤ = 1,000,000,000,000 comparisons (IMPOSSIBLE!)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Exercise 4: The 10x Challenge üèÜ\n",
                "\n",
                "**Your Mission**: Refactor `find_duplicates_slow()` to be at least **10x faster**.\n",
                "\n",
                "**Strategies**:\n",
                "1. **Hashing**: Use `collections.Counter` for O(N) counting\n",
                "2. **Sorting**: Sort first, then scan for adjacent duplicates O(N log N)\n",
                "\n",
                "You must achieve at least **10x speedup** to pass this exercise.\n",
                "Aim for **100x or more**!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TODO 5: `find_duplicates_fast()`\n",
                "\n",
                "Implement a fast duplicate finder using hashing.\n",
                "\n",
                "**üí° Hints:**\n",
                "- Use `collections.Counter(data)` to count occurrences in O(N)\n",
                "- Filter for items with count > 1\n",
                "- Return as a list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_duplicates_fast(data: list) -> list:\n",
                "    \"\"\"\n",
                "    Find duplicate values in a list using hashing.\n",
                "    \n",
                "    This is O(N) ‚Äî much faster than the nested loop approach!\n",
                "    \n",
                "    Args:\n",
                "        data: List of values to check\n",
                "    \n",
                "    Returns:\n",
                "        List of duplicate values\n",
                "    \"\"\"\n",
                "    # TODO: Implement using Counter\n",
                "    # 1. Count occurrences: counts = Counter(data)\n",
                "    # 2. Filter for duplicates: [item for item, count in counts.items() if count > 1]\n",
                "    # 3. Return the list\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Compare slow vs fast\n",
                "print(\"Comparing slow vs fast duplicate finding...\\n\")\n",
                "\n",
                "# Time the slow version (small sample)\n",
                "print(\"Slow version (10,000 items):\")\n",
                "start = time.perf_counter()\n",
                "slow_result = find_duplicates_slow(sample_users)\n",
                "slow_time = time.perf_counter() - start\n",
                "print(f\"  Time: {slow_time:.3f} seconds\")\n",
                "print(f\"  Found: {len(slow_result)} duplicates\\n\")\n",
                "\n",
                "# Time the fast version (same sample)\n",
                "print(\"Fast version (10,000 items):\")\n",
                "start = time.perf_counter()\n",
                "fast_result = find_duplicates_fast(sample_users)\n",
                "fast_time = time.perf_counter() - start\n",
                "print(f\"  Time: {fast_time:.6f} seconds\")\n",
                "print(f\"  Found: {len(fast_result)} duplicates\\n\")\n",
                "\n",
                "# Calculate speedup\n",
                "speedup = slow_time / fast_time\n",
                "print(f\"üöÄ Speedup: {speedup:.0f}x faster!\")\n",
                "\n",
                "# Verify results match\n",
                "assert set(slow_result) == set(fast_result), \"Results should match!\"\n",
                "assert speedup >= 10, f\"Need at least 10x speedup, got {speedup:.1f}x\"\n",
                "\n",
                "print(\"\\n‚úì The 10x Challenge: PASSED!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Bonus: Scale to 1 Million!\n",
                "\n",
                "Now let's see the fast version handle the **full dataset**:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load full dataset\n",
                "print(\"Loading full dataset (1M rows)...\")\n",
                "full_df = pd.read_csv(USER_LOGS_PATH)\n",
                "all_users = full_df['user_id'].tolist()\n",
                "print(f\"Loaded {len(all_users):,} user_ids\\n\")\n",
                "\n",
                "# Time the fast version on full data\n",
                "print(\"Running fast duplicate finder on 1M items...\")\n",
                "start = time.perf_counter()\n",
                "duplicates = find_duplicates_fast(all_users)\n",
                "elapsed = time.perf_counter() - start\n",
                "\n",
                "print(f\"Time: {elapsed:.3f} seconds\")\n",
                "print(f\"Found: {len(duplicates):,} duplicate user_ids\")\n",
                "print(f\"\\nüéâ Processed 1 MILLION items in under {elapsed:.1f} seconds!\")\n",
                "\n",
                "# How long would the slow version take?\n",
                "estimated_slow = (slow_time / 10_000**2) * 1_000_000**2\n",
                "print(f\"\\n‚ö†Ô∏è  Estimated time for slow version: {estimated_slow/3600:.1f} HOURS!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 7. Reflection\n",
                "\n",
                "**Your task:** Write a short reflection (3-5 sentences) answering:\n",
                "\n",
                "1. What was the most surprising performance difference you observed?\n",
                "2. How will this change how you write code in the future?\n",
                "3. When would you choose chunking over full loading?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: Write your reflection here\n",
                "reflection = \"\"\"\n",
                "Replace this text with your reflection.\n",
                "Think about what you learned about complexity at scale.\n",
                "What will you remember about O(N) vs O(N¬≤)?\n",
                "When will you use Sets instead of Lists?\n",
                "\"\"\".strip()\n",
                "\n",
                "print(\"Your reflection:\")\n",
                "print(reflection)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## 8. Save Results\n",
                "\n",
                "Finally, save all metrics to `results/lab02_metrics.json`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compile all results\n",
                "results = {\n",
                "    \"lab\": \"02_complexity_dataflow\",\n",
                "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
                "    \"dataset\": {\n",
                "        \"rows\": 1_000_000,\n",
                "        \"path\": str(USER_LOGS_PATH),\n",
                "    },\n",
                "    \"exercise_1_search\": {\n",
                "        \"list_median_ms\": search_results[\"list_median_ms\"],\n",
                "        \"set_median_ms\": search_results[\"set_median_ms\"],\n",
                "        \"speedup\": search_results[\"speedup\"],\n",
                "    },\n",
                "    \"exercise_2_dataflow\": {\n",
                "        \"full_load_sec\": full_result[\"time_sec\"],\n",
                "        \"full_load_memory_mb\": full_result[\"memory_mb\"],\n",
                "        \"chunked_sec\": chunked_result[\"time_sec\"],\n",
                "        \"chunked_peak_memory_mb\": chunked_result[\"peak_memory_mb\"],\n",
                "        \"iterator_sec\": iterator_result[\"time_sec\"],\n",
                "    },\n",
                "    \"exercise_4_optimization\": {\n",
                "        \"slow_time_sec\": slow_time,\n",
                "        \"fast_time_sec\": fast_time,\n",
                "        \"speedup\": speedup,\n",
                "    },\n",
                "    \"reflection\": reflection,\n",
                "}\n",
                "\n",
                "# Save to JSON\n",
                "with open(METRICS_PATH, \"w\") as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print(f\"‚úì Results saved to: {METRICS_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéâ Lab Complete!\n",
                "\n",
                "### What You Learned\n",
                "\n",
                "1. **Scale matters**: O(N¬≤) is fine for 1,000 items, catastrophic for 1,000,000\n",
                "2. **Use the right data structure**: Sets give O(1) lookup vs Lists O(N)\n",
                "3. **Memory hierarchy is real**: Full load vs chunking vs streaming\n",
                "4. **Profile before optimizing**: Find the actual bottleneck first!\n",
                "5. **Hashing is magic**: Counter turns O(N¬≤) into O(N)\n",
                "\n",
                "### Files to Submit\n",
                "\n",
                "1. `notebooks/lab02_complexity_dataflow.ipynb` (this notebook, with all cells executed)\n",
                "2. `results/lab02_metrics.json` (generated by this notebook)\n",
                "\n",
                "---\n",
                "\n",
                "**Next Lab**: We'll explore parallel processing and distributed computing!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}