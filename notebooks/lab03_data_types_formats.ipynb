{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lab 03: Data Types and Efficient Formats\n",
    "\n",
    "**Course:** Big Data\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ‘¤ Student Information\n",
    "\n",
    "**Name:** `Your Name Here`\n",
    "\n",
    "**Date:** `DD/MM/YYYY`\n",
    "\n",
    "---\n",
    "\n",
    "**Goal:** Master data type optimization and efficient storage formats to achieve significant memory and performance improvements.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Optimize Data Types**: Reduce memory usage 5-10x through smart dtype selection\n",
    "2. **Compare Storage Formats**: Understand trade-offs between CSV, Parquet, and Feather\n",
    "3. **Configure Parquet**: Tune compression and row group settings\n",
    "4. **Implement Partitioning**: Structure data for fast analytical queries\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Fill in your information above** before starting the lab\n",
    "2. Read each cell carefully before running it\n",
    "3. Implement the **TODO functions** when you see them\n",
    "4. Run cells **from top to bottom** (Shift+Enter)\n",
    "5. Check that output makes sense after each cell\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ðŸ“š Libraries Used in This Lab\n",
    "\n",
    "### Core Libraries\n",
    "\n",
    "- **`pandas`** - DataFrame operations and I/O\n",
    "- **`numpy`** - Random data generation\n",
    "- **`pyarrow`** - Parquet and Arrow format support\n",
    "- **`time`** - Performance measurement\n",
    "\n",
    "### Why These Libraries?\n",
    "\n",
    "- **PyArrow**: Industry-standard for columnar data, enables Parquet with advanced features\n",
    "- **Pandas**: Our familiar DataFrame interface with dtype control\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ The Cost of Bad Choices\n",
    "\n",
    "**Real-world example**: A 100M row sales dataset\n",
    "\n",
    "| Approach | Disk Size | RAM Usage | Load Time |\n",
    "|----------|-----------|-----------|----------|\n",
    "| Naive (object, CSV) | 50 GB | 80 GB | 15 min |\n",
    "| Optimized (proper types, Parquet) | 2 GB | 5 GB | 20 sec |\n",
    "\n",
    "**That's 25x smaller and 45x faster!**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "print(\"âœ“ All imports successful!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"PyArrow version: {pa.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "DATA_PROCESSED = Path(\"../data/processed\")\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "\n",
    "# File paths for this lab\n",
    "ECOMMERCE_CSV = DATA_RAW / \"ecommerce_5m.csv\"\n",
    "FORMATS_DIR = DATA_PROCESSED / \"formats\"\n",
    "PARTITION_DIR = DATA_PROCESSED / \"partitioned\"\n",
    "METRICS_PATH = RESULTS_DIR / \"lab03_metrics.json\"\n",
    "\n",
    "# Ensure directories exist\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "FORMATS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PARTITION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Paths defined:\")\n",
    "print(f\"  Source CSV: {ECOMMERCE_CSV}\")\n",
    "print(f\"  Formats: {FORMATS_DIR}\")\n",
    "print(f\"  Partitioned: {PARTITION_DIR}\")\n",
    "print(f\"  Metrics: {METRICS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dataset Generation\n",
    "\n",
    "First, we generate a synthetic e-commerce dataset with 5 million rows.\n",
    "\n",
    "**Columns:**\n",
    "- `order_id`: Unique order identifier\n",
    "- `product_id`: Product ID (1-50,000)\n",
    "- `category`: Product category (15 unique values)\n",
    "- `price`: Product price (0.01-999.99)\n",
    "- `quantity`: Quantity ordered (1-100)\n",
    "- `country`: Customer country (30 unique values)\n",
    "- `timestamp`: Order timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "### TODO 1: `generate_ecommerce_data()`\n",
    "\n",
    "Generate a synthetic e-commerce dataset.\n",
    "\n",
    "**ðŸ’¡ Hints:**\n",
    "- Use `np.random.seed(seed)` for reproducibility\n",
    "- Use `np.random.randint()` for integer columns\n",
    "- Use `np.random.choice()` for category/country columns\n",
    "- Use `np.random.uniform()` for price\n",
    "- Use `pd.date_range()` for timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecommerce_data(path: Path, n_rows: int = 5_000_000, seed: int = 42) -> dict:\n",
    "    \"\"\"\n",
    "    Generate a synthetic e-commerce dataset.\n",
    "    \n",
    "    Args:\n",
    "        path: Where to save the CSV\n",
    "        n_rows: Number of rows (default 5 million)\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with: {\"rows\": int, \"cols\": int, \"size_mb\": float}\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Step 1: Set random seed\n",
    "    # Step 2: Define categories list (15 items)\n",
    "    # Step 3: Define countries list (30 items)\n",
    "    # Step 4: Generate each column\n",
    "    # Step 5: Create DataFrame\n",
    "    # Step 6: Save to CSV\n",
    "    # Step 7: Return metadata\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset (only if it doesn't exist)\n",
    "if not ECOMMERCE_CSV.exists():\n",
    "    print(\"Generating 5 million row e-commerce dataset...\")\n",
    "    print(\"(This may take 1-2 minutes)\\n\")\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    metadata = generate_ecommerce_data(ECOMMERCE_CSV, n_rows=5_000_000)\n",
    "    elapsed = time.perf_counter() - start\n",
    "    \n",
    "    print(f\"Generated in {elapsed:.1f} seconds\")\n",
    "    print(f\"Rows: {metadata['rows']:,}\")\n",
    "    print(f\"Size: {metadata['size_mb']:.1f} MB\")\n",
    "else:\n",
    "    size_mb = ECOMMERCE_CSV.stat().st_size / 1e6\n",
    "    print(f\"Dataset already exists: {size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: Data Type Optimization ðŸŽ¯\n",
    "\n",
    "### Part 1A: Baseline Measurement\n",
    "\n",
    "First, let's see how much memory pandas uses with default dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with default dtypes\n",
    "print(\"Loading CSV with default dtypes...\")\n",
    "start = time.perf_counter()\n",
    "df_baseline = pd.read_csv(ECOMMERCE_CSV)\n",
    "load_time_baseline = time.perf_counter() - start\n",
    "\n",
    "print(f\"Load time: {load_time_baseline:.2f} seconds\")\n",
    "print(f\"\\nDataFrame shape: {df_baseline.shape}\")\n",
    "print(f\"\\nColumn dtypes:\")\n",
    "print(df_baseline.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_memory(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Measure memory usage of a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to measure\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with total and per-column memory in MB\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # 1. Use df.memory_usage(deep=True) to get accurate memory\n",
    "    # 2. Calculate total memory in MB\n",
    "    # 3. Create dict with per-column info (dtype, memory, nunique)\n",
    "    pass\n",
    "\n",
    "\n",
    "# Measure baseline memory\n",
    "baseline_memory = measure_memory(df_baseline)\n",
    "print(f\"\\nTotal memory: {baseline_memory['total_mb']:.2f} MB\")\n",
    "print(\"\\nPer-column breakdown:\")\n",
    "for col, info in baseline_memory['columns'].items():\n",
    "    print(f\"  {col}: {info['dtype']} - {info['memory_mb']:.2f} MB ({info['nunique']:,} unique)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### Part 1B: Type Analysis\n",
    "\n",
    "Let's analyze each column to determine the optimal type:\n",
    "\n",
    "| Column | Current | Range/Values | Optimal Type |\n",
    "|--------|---------|--------------|-------------|\n",
    "| order_id | int64 | 0 to 5M | ? |\n",
    "| product_id | int64 | 1 to 50,000 | ? |\n",
    "| category | object | 15 unique | ? |\n",
    "| price | float64 | 0.01 to 999.99 | ? |\n",
    "| quantity | int64 | 1 to 100 | ? |\n",
    "| country | object | 30 unique | ? |\n",
    "| timestamp | object | dates | ? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze value ranges\n",
    "print(\"Value ranges for numeric columns:\")\n",
    "for col in ['order_id', 'product_id', 'quantity']:\n",
    "    print(f\"  {col}: {df_baseline[col].min()} to {df_baseline[col].max()}\")\n",
    "\n",
    "print(f\"\\n  price: {df_baseline['price'].min():.2f} to {df_baseline['price'].max():.2f}\")\n",
    "\n",
    "print(\"\\nUnique values for string columns:\")\n",
    "print(f\"  category: {df_baseline['category'].nunique()} unique\")\n",
    "print(f\"  country: {df_baseline['country'].nunique()} unique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "### TODO 3: Define Optimal Types\n",
    "\n",
    "Based on your analysis, fill in the optimal types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_dtypes() -> dict:\n",
    "    \"\"\"\n",
    "    Return the optimal dtypes for the ecommerce dataset.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping column names to dtype strings\n",
    "    \"\"\"\n",
    "    # TODO: Fill in the optimal types based on your analysis\n",
    "    return {\n",
    "        'order_id': '???',      # 0 to 5M - which int type?\n",
    "        'product_id': '???',    # 1 to 50000 - which int type?\n",
    "        'category': '???',      # 15 unique strings\n",
    "        'price': '???',         # 0.01 to 999.99\n",
    "        'quantity': '???',      # 1 to 100 - which int type?\n",
    "        'country': '???',       # 30 unique strings\n",
    "    }\n",
    "\n",
    "\n",
    "optimal_dtypes = get_optimal_dtypes()\n",
    "print(\"Optimal dtypes:\")\n",
    "for col, dtype in optimal_dtypes.items():\n",
    "    print(f\"  {col}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "### Part 1C: Optimized Loading\n",
    "\n",
    "Now let's reload with optimized types and measure the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with optimized dtypes\n",
    "print(\"Loading CSV with optimized dtypes...\")\n",
    "start = time.perf_counter()\n",
    "df_optimized = pd.read_csv(\n",
    "    ECOMMERCE_CSV,\n",
    "    dtype=optimal_dtypes,\n",
    "    parse_dates=['timestamp']\n",
    ")\n",
    "load_time_optimized = time.perf_counter() - start\n",
    "\n",
    "print(f\"Load time: {load_time_optimized:.2f} seconds\")\n",
    "print(f\"\\nColumn dtypes:\")\n",
    "print(df_optimized.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure optimized memory\n",
    "optimized_memory = measure_memory(df_optimized)\n",
    "\n",
    "print(f\"Baseline memory: {baseline_memory['total_mb']:.2f} MB\")\n",
    "print(f\"Optimized memory: {optimized_memory['total_mb']:.2f} MB\")\n",
    "print(f\"\\nReduction: {baseline_memory['total_mb'] / optimized_memory['total_mb']:.1f}x\")\n",
    "\n",
    "print(\"\\nPer-column comparison:\")\n",
    "for col in baseline_memory['columns']:\n",
    "    before = baseline_memory['columns'][col]['memory_mb']\n",
    "    after = optimized_memory['columns'][col]['memory_mb']\n",
    "    reduction = before / after if after > 0 else 0\n",
    "    print(f\"  {col}: {before:.1f} MB â†’ {after:.1f} MB ({reduction:.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "### Part 1D: Speed Impact\n",
    "\n",
    "Smaller types aren't just about memory â€” they're also faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark groupby operation\n",
    "print(\"Benchmarking groupby operation...\\n\")\n",
    "\n",
    "# Baseline\n",
    "start = time.perf_counter()\n",
    "_ = df_baseline.groupby('category')['price'].sum()\n",
    "groupby_baseline = time.perf_counter() - start\n",
    "\n",
    "# Optimized\n",
    "start = time.perf_counter()\n",
    "_ = df_optimized.groupby('category')['price'].sum()\n",
    "groupby_optimized = time.perf_counter() - start\n",
    "\n",
    "print(f\"Groupby baseline: {groupby_baseline:.4f} sec\")\n",
    "print(f\"Groupby optimized: {groupby_optimized:.4f} sec\")\n",
    "print(f\"Speedup: {groupby_baseline / groupby_optimized:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark filter operation\n",
    "print(\"Benchmarking filter operation...\\n\")\n",
    "\n",
    "# Baseline\n",
    "start = time.perf_counter()\n",
    "_ = df_baseline[df_baseline['country'] == 'Spain']\n",
    "filter_baseline = time.perf_counter() - start\n",
    "\n",
    "# Optimized\n",
    "start = time.perf_counter()\n",
    "_ = df_optimized[df_optimized['country'] == 'Spain']\n",
    "filter_optimized = time.perf_counter() - start\n",
    "\n",
    "print(f\"Filter baseline: {filter_baseline:.4f} sec\")\n",
    "print(f\"Filter optimized: {filter_optimized:.4f} sec\")\n",
    "print(f\"Speedup: {filter_baseline / filter_optimized:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Key Insight: Category dtype\n",
    "\n",
    "The `category` dtype is especially powerful:\n",
    "\n",
    "```python\n",
    "# Internally stored as:\n",
    "# Dictionary: {0: 'Electronics', 1: 'Clothing', ...}\n",
    "# Codes: [0, 1, 0, 2, 1, ...]  (integers!)\n",
    "```\n",
    "\n",
    "Benefits:\n",
    "- Groupby operates on integers, not strings\n",
    "- Comparisons use integer codes\n",
    "- Memory scales with unique values, not row count\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## Exercise 2: Format Comparison ðŸ“Š\n",
    "\n",
    "Now let's compare different storage formats.\n",
    "\n",
    "### Part 2A & 2B: Write and Measure Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_formats(df: pd.DataFrame, base_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Benchmark different file formats for writing and reading.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to benchmark\n",
    "        base_path: Directory to save files\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with timing and size results\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # For each format (CSV, CSV.gz, Parquet variants, Feather):\n",
    "    # 1. Time the write operation\n",
    "    # 2. Record file size\n",
    "    # 3. Time full read\n",
    "    # 4. Time partial read (3 columns) where supported\n",
    "    pass\n",
    "\n",
    "\n",
    "# Run benchmarks\n",
    "print(\"Benchmarking file formats...\")\n",
    "print(\"(This may take a few minutes)\\n\")\n",
    "\n",
    "format_results = benchmark_formats(df_optimized, FORMATS_DIR)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nResults:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Format':<20} {'Size (MB)':<12} {'Write (s)':<12} {'Read (s)':<12} {'3-col (s)':<12}\")\n",
    "print(\"-\" * 70)\n",
    "for fmt, data in format_results.items():\n",
    "    partial = f\"{data['read_partial_sec']:.3f}\" if data['read_partial_sec'] else \"N/A\"\n",
    "    print(f\"{fmt:<20} {data['size_mb']:<12.1f} {data['write_sec']:<12.3f} {data['read_full_sec']:<12.3f} {partial:<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Key Insights: Formats\n",
    "\n",
    "| Format | Best For |\n",
    "|--------|----------|\n",
    "| CSV | Universal exchange, debugging, small files |\n",
    "| Parquet (zstd) | Long-term storage, analytics |\n",
    "| Feather | Fast Python/R exchange, caching |\n",
    "\n",
    "**Column Selection**: Only Parquet and Feather can read specific columns without loading the entire file!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Exercise 3: Parquet Deep Dive ðŸ”¬\n",
    "\n",
    "### Part 3A: Inspect Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_parquet(path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Inspect Parquet file metadata.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to Parquet file\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with metadata information\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # 1. Open with pq.ParquetFile(path)\n",
    "    # 2. Get num_row_groups, schema, etc.\n",
    "    # 3. For each row group, get statistics\n",
    "    pass\n",
    "\n",
    "\n",
    "# Inspect the Parquet file\n",
    "pq_path = FORMATS_DIR / 'data_zstd.parquet'\n",
    "if pq_path.exists():\n",
    "    pq_info = inspect_parquet(pq_path)\n",
    "    print(f\"Row Groups: {pq_info['num_row_groups']}\")\n",
    "    print(f\"Total Rows: {pq_info['num_rows']:,}\")\n",
    "    print(f\"\\nSchema:\\n{pq_info['schema']}\")\n",
    "else:\n",
    "    print(\"Run the format benchmark first to generate the Parquet file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "### Part 3B: Row Group Size Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_row_group_sizes(df: pd.DataFrame, base_path: Path, \n",
    "                              sizes: list = [10_000, 100_000, 1_000_000]) -> dict:\n",
    "    \"\"\"\n",
    "    Benchmark different row group sizes.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to benchmark\n",
    "        base_path: Directory to save files\n",
    "        sizes: List of row group sizes to test\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results for each size\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # For each row group size:\n",
    "    # 1. Write with df.to_parquet(path, row_group_size=size)\n",
    "    # 2. Count row groups with pq.ParquetFile\n",
    "    # 3. Time read operation\n",
    "    pass\n",
    "\n",
    "\n",
    "# Run benchmark\n",
    "print(\"Benchmarking row group sizes...\\n\")\n",
    "rg_results = benchmark_row_group_sizes(df_optimized, FORMATS_DIR)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Row Group Size':<20} {'# Groups':<12} {'Size (MB)':<12} {'Read (s)':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for size, data in rg_results.items():\n",
    "    print(f\"{size:<20,} {data['num_row_groups']:<12} {data['file_size_mb']:<12.1f} {data['read_sec']:<12.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "### Part 3C: Predicate Pushdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_predicate_pushdown(path: Path, column: str, threshold: float) -> dict:\n",
    "    \"\"\"\n",
    "    Benchmark reading with and without predicate pushdown.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to Parquet file\n",
    "        column: Column to filter on\n",
    "        threshold: Value threshold for filter\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with timing results\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # 1. Read without filter, time it\n",
    "    # 2. Read with filters=[(column, '>', threshold)], time it\n",
    "    # 3. Calculate speedup\n",
    "    pass\n",
    "\n",
    "\n",
    "# Run predicate pushdown benchmark\n",
    "pq_path = FORMATS_DIR / 'data_zstd.parquet'\n",
    "if pq_path.exists():\n",
    "    print(\"Benchmarking predicate pushdown...\\n\")\n",
    "    pushdown_results = benchmark_predicate_pushdown(pq_path, 'price', 500.0)\n",
    "    \n",
    "    print(f\"Without filter: {pushdown_results['no_filter_sec']:.3f} sec ({pushdown_results['no_filter_rows']:,} rows)\")\n",
    "    print(f\"With filter: {pushdown_results['with_filter_sec']:.3f} sec ({pushdown_results['with_filter_rows']:,} rows)\")\n",
    "    print(f\"\\nSpeedup: {pushdown_results['speedup']:.2f}x\")\n",
    "else:\n",
    "    print(\"Run the format benchmark first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Key Insight: Predicate Pushdown\n",
    "\n",
    "Parquet stores min/max statistics for each column chunk. When you filter:\n",
    "\n",
    "1. Parquet checks statistics first\n",
    "2. Skips entire row groups that can't match\n",
    "3. Only reads relevant data\n",
    "\n",
    "This is why analytical queries on Parquet are so fast!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Exercise 4: Partitioning Strategies ðŸ“‚\n",
    "\n",
    "### Part 4A: Add Partition Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_partition_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add year, month, day columns from timestamp for partitioning.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'timestamp' column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with added partition columns\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # 1. Convert timestamp to datetime if needed\n",
    "    # 2. Extract year, month, day\n",
    "    # 3. Use smallest int types (uint16, uint8)\n",
    "    pass\n",
    "\n",
    "\n",
    "# Add partition columns\n",
    "df_partitioned = add_partition_columns(df_optimized)\n",
    "print(\"Added partition columns:\")\n",
    "print(df_partitioned[['timestamp', 'year', 'month', 'day']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-36",
   "metadata": {},
   "source": [
    "### Part 4B: Implement Partitioning Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_partitioning(df: pd.DataFrame, base_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Benchmark different partitioning strategies.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with partition columns\n",
    "        base_path: Directory to save partitioned data\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results for each strategy\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Strategy 1: No partitioning\n",
    "    # Strategy 2: By year/month\n",
    "    # Strategy 3: By year/month/day\n",
    "    # Strategy 4: By category\n",
    "    # For each: measure write time, count files, measure size\n",
    "    pass\n",
    "\n",
    "\n",
    "# Run partitioning benchmark\n",
    "print(\"Creating partitioned datasets...\")\n",
    "print(\"(This may take a few minutes)\\n\")\n",
    "\n",
    "partition_results = benchmark_partitioning(df_partitioned, PARTITION_DIR)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Strategy':<25} {'Files':<10} {'Size (MB)':<12} {'Write (s)':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for name, data in partition_results.items():\n",
    "    print(f\"{name:<25} {data['num_files']:<10} {data['size_mb']:<12.1f} {data['write_sec']:<12.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "### Part 4C: Benchmark Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_partition_queries(base_path: Path, year: int, month: int, \n",
    "                                 day: int, category: str) -> dict:\n",
    "    \"\"\"\n",
    "    Benchmark query performance across partitioning strategies.\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base directory with partitioned data\n",
    "        year, month, day: Date to filter for queries\n",
    "        category: Category to filter for queries\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with query times for each strategy\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Query 1: Specific day\n",
    "    # Query 2: Category for one month\n",
    "    # Query 3: Full aggregation\n",
    "    # For each strategy, time each query\n",
    "    pass\n",
    "\n",
    "\n",
    "# Run query benchmarks\n",
    "print(\"Benchmarking queries across partitioning strategies...\\n\")\n",
    "\n",
    "query_results = benchmark_partition_queries(\n",
    "    PARTITION_DIR,\n",
    "    year=2024, month=1, day=15,\n",
    "    category='Electronics'\n",
    ")\n",
    "\n",
    "print(\"Query Times (seconds):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Strategy':<25} {'Day Query':<15} {'Cat+Month':<15} {'Full Agg':<15}\")\n",
    "print(\"-\" * 70)\n",
    "for name, data in query_results.items():\n",
    "    day_q = f\"{data['query_day_sec']:.3f}\" if data['query_day_sec'] else \"N/A\"\n",
    "    cat_q = f\"{data['query_category_month_sec']:.3f}\" if data['query_category_month_sec'] else \"N/A\"\n",
    "    full_q = f\"{data['query_full_agg_sec']:.3f}\" if data['query_full_agg_sec'] else \"N/A\"\n",
    "    print(f\"{name:<25} {day_q:<15} {cat_q:<15} {full_q:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Key Insight: Partitioning Trade-offs\n",
    "\n",
    "| Query Type | Best Strategy |\n",
    "|------------|---------------|\n",
    "| Specific day | Partition by year/month/day |\n",
    "| Category analysis | Partition by category |\n",
    "| Full aggregation | No partitioning (less overhead) |\n",
    "\n",
    "**Rule**: Partition by columns you **filter** on frequently!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": [
    "## 5. Reflection\n",
    "\n",
    "**Your task:** Write a short reflection (3-5 sentences) answering:\n",
    "\n",
    "1. What was the biggest memory reduction you achieved with dtype optimization?\n",
    "2. Which storage format would you choose for a data warehouse? Why?\n",
    "3. When would partitioning hurt rather than help performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your reflection here\n",
    "reflection = \"\"\"\n",
    "Replace this text with your reflection.\n",
    "Think about what you learned about data types and formats.\n",
    "What will you do differently in your future projects?\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Your reflection:\")\n",
    "print(reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "results = {\n",
    "    \"lab\": \"03_data_types_formats\",\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "    \"exercise_1_dtypes\": {\n",
    "        \"baseline_memory_mb\": baseline_memory['total_mb'],\n",
    "        \"optimized_memory_mb\": optimized_memory['total_mb'],\n",
    "        \"reduction_factor\": round(baseline_memory['total_mb'] / optimized_memory['total_mb'], 2),\n",
    "        \"groupby_speedup\": round(groupby_baseline / groupby_optimized, 2),\n",
    "        \"filter_speedup\": round(filter_baseline / filter_optimized, 2),\n",
    "    },\n",
    "    \"exercise_2_formats\": format_results,\n",
    "    \"exercise_3_parquet\": {\n",
    "        \"row_group_sizes\": rg_results,\n",
    "        \"predicate_pushdown\": pushdown_results if 'pushdown_results' in dir() else None,\n",
    "    },\n",
    "    \"exercise_4_partitioning\": {\n",
    "        \"strategies\": partition_results,\n",
    "        \"query_benchmarks\": query_results,\n",
    "    },\n",
    "    \"reflection\": reflection,\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"âœ“ Results saved to: {METRICS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ Lab Complete!\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Data Type Optimization**: Choosing the right dtype can reduce memory 5-10x\n",
    "2. **Category dtype**: Essential for repeated strings, speeds up groupby operations\n",
    "3. **Column-Oriented Storage**: Parquet reads only columns you need\n",
    "4. **Compression Trade-offs**: Zstd offers the best balance of speed and ratio\n",
    "5. **Partitioning**: Powerful for selective queries, but can hurt full scans\n",
    "\n",
    "### Optimization Checklist\n",
    "\n",
    "- âœ… Use smallest int type that fits your data\n",
    "- âœ… Use `category` for strings with <50% unique values\n",
    "- âœ… Use `float32` unless you need high precision\n",
    "- âœ… Store data as Parquet with Zstd compression\n",
    "- âœ… Partition by columns you filter on frequently\n",
    "\n",
    "### Files to Submit\n",
    "\n",
    "1. `notebooks/lab03_data_types_formats.ipynb` (this notebook)\n",
    "2. `results/lab03_metrics.json`\n",
    "\n",
    "---\n",
    "\n",
    "**Next Lab**: We'll explore parallel processing and distributed computing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
