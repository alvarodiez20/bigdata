{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04: Efficient Formats and Vectorization\n",
    "\n",
    "**Course:** Big Data\n",
    "\n",
    "---\n",
    "\n",
    "## Student Information\n",
    "\n",
    "**Name:** `Your Name Here`\n",
    "\n",
    "**Date:** `DD/MM/YYYY`\n",
    "\n",
    "---\n",
    "\n",
    "**Goal:** Compare storage formats (CSV, Parquet, Feather) and master vectorization to process data efficiently.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Compare Storage Formats**: Understand trade-offs between CSV, Parquet (Snappy, Zstd), and Feather\n",
    "2. **Benchmark I/O**: Measure read/write speed and disk usage for each format\n",
    "3. **Vectorize Operations**: Replace slow Python loops with NumPy/Pandas operations (100-200x speedup)\n",
    "4. **Use Broadcasting**: Apply operations across arrays without explicit loops\n",
    "5. **Build Optimized Pipelines**: Combine efficient formats + vectorization for maximum performance\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Fill in your information above** before starting the lab\n",
    "2. Read each cell carefully before running it\n",
    "3. Implement the **TODO functions** when you see them\n",
    "4. Run cells **from top to bottom** (Shift+Enter)\n",
    "5. Check that output makes sense after each cell\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries Used in This Lab\n",
    "\n",
    "### Core Libraries\n",
    "\n",
    "- **`numpy`** - Vectorized numerical operations\n",
    "- **`pandas`** - DataFrame operations and I/O\n",
    "- **`pyarrow`** - Parquet/Feather engine\n",
    "- **`time`** - Performance measurement\n",
    "- **`os`** - File size measurement\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "Two key optimizations can transform your data pipeline:\n",
    "\n",
    "1. **Format choice**: Parquet can be 5-10x smaller and faster than CSV\n",
    "2. **Vectorization**: NumPy operations are 100-200x faster than Python loops\n",
    "\n",
    "Combined, these can turn a 10-minute pipeline into a few seconds.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "\n",
    "print(\"Imports successful!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyArrow version: {pyarrow.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directories\n",
    "DATA_RAW = Path(\"../data/raw\")\n",
    "DATA_PROCESSED = Path(\"../data/processed\")\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "\n",
    "# File paths for this lab\n",
    "VENTAS_CSV = DATA_RAW / \"ventas.csv\"\n",
    "VENTAS_SNAPPY = DATA_PROCESSED / \"ventas_snappy.parquet\"\n",
    "VENTAS_ZSTD = DATA_PROCESSED / \"ventas_zstd.parquet\"\n",
    "VENTAS_NONE = DATA_PROCESSED / \"ventas_none.parquet\"\n",
    "VENTAS_FEATHER = DATA_PROCESSED / \"ventas.feather\"\n",
    "METRICS_PATH = RESULTS_DIR / \"lab04_metrics.json\"\n",
    "\n",
    "# Ensure directories exist\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Paths defined:\")\n",
    "print(f\"  CSV: {VENTAS_CSV}\")\n",
    "print(f\"  Parquet (snappy): {VENTAS_SNAPPY}\")\n",
    "print(f\"  Metrics: {METRICS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Dataset Generation\n",
    "\n",
    "We create a realistic sales dataset with 5 million rows to benchmark formats and vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 1: `generate_ventas()`\n",
    "\n",
    "Generate a synthetic sales dataset.\n",
    "\n",
    "**Hints:**\n",
    "- Use `np.random.seed(seed)` for reproducibility\n",
    "- Use `pd.date_range()` for dates with frequency `'s'` (seconds)\n",
    "- Use `np.random.choice()` for categorical columns\n",
    "- Use `np.random.uniform()` for price, `np.random.randint()` for quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ventas(n: int = 5_000_000, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a synthetic sales dataset.\n",
    "    \n",
    "    Args:\n",
    "        n: Number of rows\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: id, fecha, categoria, producto, precio, cantidad, ciudad\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # Step 1: Set random seed with np.random.seed(seed)\n",
    "    # Step 2: Create DataFrame with columns:\n",
    "    #   - 'id': range(n)\n",
    "    #   - 'fecha': pd.date_range('2020-01-01', periods=n, freq='s')\n",
    "    #   - 'categoria': np.random.choice(['Electronica', 'Ropa', 'Hogar', 'Deportes'], n)\n",
    "    #   - 'producto': np.random.choice([f'prod_{i}' for i in range(1000)], n)\n",
    "    #   - 'precio': np.random.uniform(1, 1000, n).round(2)\n",
    "    #   - 'cantidad': np.random.randint(1, 50, n)\n",
    "    #   - 'ciudad': np.random.choice(['Madrid', 'Barcelona', 'Valencia', 'Sevilla', 'Bilbao'], n)\n",
    "    # Step 3: Return DataFrame\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "print(\"Generating 5 million row sales dataset...\")\n",
    "print(\"(This may take 30-60 seconds)\\n\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "df = generate_ventas(n=5_000_000)\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"Generated in {elapsed:.1f} seconds\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory: {df.memory_usage(deep=True).sum() / 1e6:.1f} MB\")\n",
    "    print(f\"\\nSample:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"TODO: Implement generate_ventas()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 1: CSV vs Parquet vs Feather - Practical Comparison (25 min)\n",
    "\n",
    "**Objective**: Experience firsthand the differences between storage formats.\n",
    "\n",
    "### Format Overview\n",
    "\n",
    "| Format | Type | Compression | Column Selection | Predicate Pushdown |\n",
    "|--------|------|-------------|------------------|--------------------|\n",
    "| CSV | Row-based, text | None | No (reads all) | No |\n",
    "| Parquet (Snappy) | Columnar, binary | Fast, moderate ratio | Yes | Yes |\n",
    "| Parquet (Zstd) | Columnar, binary | Slower, best ratio | Yes | Yes |\n",
    "| Parquet (None) | Columnar, binary | None | Yes | Yes |\n",
    "| Feather | Columnar, binary | Optional (LZ4) | Yes | No |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: `save_all_formats()`\n",
    "\n",
    "Save the DataFrame in all formats and measure file sizes.\n",
    "\n",
    "**Hints:**\n",
    "- Use `df.to_csv(path, index=False)`\n",
    "- Use `df.to_parquet(path, compression='snappy')`, `compression='zstd'`, `compression=None`\n",
    "- Use `df.to_feather(path)`\n",
    "- Use `os.path.getsize(path) / 1024**2` for size in MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_formats(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Save DataFrame in CSV, Parquet (snappy, zstd, none), and Feather.\n",
    "    Measure write time and file size for each.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to save\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with format -> {\"write_sec\": float, \"size_mb\": float}\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # For each format:\n",
    "    #   1. Record start time with time.perf_counter()\n",
    "    #   2. Save the DataFrame\n",
    "    #   3. Record elapsed time\n",
    "    #   4. Measure file size with os.path.getsize() / 1024**2\n",
    "    #   5. Store results in dictionary\n",
    "    #\n",
    "    # Formats to save:\n",
    "    #   - CSV:             df.to_csv(VENTAS_CSV, index=False)\n",
    "    #   - Parquet Snappy:  df.to_parquet(VENTAS_SNAPPY, compression='snappy')\n",
    "    #   - Parquet Zstd:    df.to_parquet(VENTAS_ZSTD, compression='zstd')\n",
    "    #   - Parquet None:    df.to_parquet(VENTAS_NONE, compression=None)\n",
    "    #   - Feather:         df.to_feather(VENTAS_FEATHER)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in all formats\n",
    "print(\"Saving in all formats...\\n\")\n",
    "\n",
    "format_results = save_all_formats(df)\n",
    "\n",
    "if format_results:\n",
    "    print(f\"{'Format':<20} {'Size (MB)':>10} {'Write (s)':>10}\")\n",
    "    print(\"-\" * 42)\n",
    "    for fmt, info in format_results.items():\n",
    "        print(f\"{fmt:<20} {info['size_mb']:>10.1f} {info['write_sec']:>10.2f}\")\n",
    "    \n",
    "    # Calculate compression ratios vs CSV\n",
    "    csv_size = format_results['csv']['size_mb']\n",
    "    print(f\"\\nCompression ratios vs CSV ({csv_size:.1f} MB):\")\n",
    "    for fmt, info in format_results.items():\n",
    "        if fmt != 'csv':\n",
    "            ratio = csv_size / info['size_mb']\n",
    "            print(f\"  {fmt}: {ratio:.1f}x smaller\")\n",
    "else:\n",
    "    print(\"TODO: Implement save_all_formats()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 3: `benchmark_reads()`\n",
    "\n",
    "Benchmark read performance for each format.\n",
    "\n",
    "**Hints:**\n",
    "- Full read: `pd.read_csv()`, `pd.read_parquet()`, `pd.read_feather()`\n",
    "- Selective read (2 columns): use `usecols=` for CSV, `columns=` for Parquet/Feather\n",
    "- Filtered read: use `filters=[('categoria', '==', 'Electronica')]` for Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_reads(n_runs: int = 3) -> dict:\n",
    "    \"\"\"\n",
    "    Benchmark read performance for all formats.\n",
    "    \n",
    "    Tests:\n",
    "    - Full read (all columns, all rows)\n",
    "    - Selective read (only 'precio' and 'cantidad' columns)\n",
    "    - Filtered read (only 'Electronica' category, Parquet only)\n",
    "    \n",
    "    Args:\n",
    "        n_runs: Number of runs for timing (use median)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with benchmark results\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # For each test, run n_runs times and take the median time.\n",
    "    #\n",
    "    # Test 1 - Full read:\n",
    "    #   - pd.read_csv(VENTAS_CSV)\n",
    "    #   - pd.read_parquet(VENTAS_SNAPPY)\n",
    "    #   - pd.read_feather(VENTAS_FEATHER)\n",
    "    #\n",
    "    # Test 2 - Selective read (2 columns: 'precio', 'cantidad'):\n",
    "    #   - pd.read_csv(VENTAS_CSV, usecols=['precio', 'cantidad'])\n",
    "    #   - pd.read_parquet(VENTAS_SNAPPY, columns=['precio', 'cantidad'])\n",
    "    #\n",
    "    # Test 3 - Filtered read (Parquet with predicate pushdown):\n",
    "    #   - pd.read_parquet(VENTAS_SNAPPY, filters=[('categoria', '==', 'Electronica')])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run read benchmarks\n",
    "print(\"Running read benchmarks (this may take a few minutes)...\\n\")\n",
    "\n",
    "read_results = benchmark_reads()\n",
    "\n",
    "if read_results:\n",
    "    for test_name, timings in read_results.items():\n",
    "        print(f\"\\n{test_name}:\")\n",
    "        for fmt, sec in timings.items():\n",
    "            print(f\"  {fmt:<20} {sec:.3f} sec\")\n",
    "    \n",
    "    # Speedup vs CSV\n",
    "    if 'full_read' in read_results:\n",
    "        csv_time = read_results['full_read'].get('csv', 0)\n",
    "        if csv_time > 0:\n",
    "            print(f\"\\nFull read speedup vs CSV ({csv_time:.2f}s):\")\n",
    "            for fmt, sec in read_results['full_read'].items():\n",
    "                if fmt != 'csv':\n",
    "                    print(f\"  {fmt}: {csv_time / sec:.1f}x faster\")\n",
    "else:\n",
    "    print(\"TODO: Implement benchmark_reads()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight: Why Parquet is Faster\n",
    "\n",
    "**CSV** (row-based, text):\n",
    "- Must read ALL data even for 2 columns\n",
    "- Must parse text to numbers\n",
    "- No metadata about data types\n",
    "\n",
    "**Parquet** (columnar, binary):\n",
    "- Reads only requested columns (column pruning)\n",
    "- Data already in binary format (no parsing)\n",
    "- Built-in statistics for predicate pushdown\n",
    "- Compression reduces I/O\n",
    "\n",
    "**Feather** (columnar, binary):\n",
    "- Fastest read/write (minimal overhead)\n",
    "- Good for intermediate data (between pipeline steps)\n",
    "- Less compression than Parquet\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Rewrite Loops to Vectorized (25 min)\n",
    "\n",
    "**Objective**: Practice identifying and vectorizing slow loop-based code.\n",
    "\n",
    "### Why Python Loops Are Slow\n",
    "\n",
    "Each Python loop iteration involves ~200 CPU instructions:\n",
    "- Interpret bytecode, look up variables, check types, find methods, create stack frames...\n",
    "\n",
    "**NumPy**: 1-2 CPU instructions (compiled C code)\n",
    "\n",
    "**Result**: 100-200x speedup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data for vectorization exercises\n",
    "print(\"Loading sample data for vectorization exercises...\")\n",
    "df_sample = pd.read_parquet(VENTAS_SNAPPY)\n",
    "print(f\"Loaded {len(df_sample):,} rows\")\n",
    "print(f\"Columns: {list(df_sample.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2A: Distance Calculation\n",
    "\n",
    "Convert a loop-based Euclidean distance calculation to NumPy broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original slow implementation\n",
    "def calculate_distances_slow(points_a, points_b):\n",
    "    \"\"\"Calculate Euclidean distances using a loop.\"\"\"\n",
    "    distances = []\n",
    "    for i in range(len(points_a)):\n",
    "        dist = math.sqrt(\n",
    "            (points_a[i][0] - points_b[i][0])**2 +\n",
    "            (points_a[i][1] - points_b[i][1])**2\n",
    "        )\n",
    "        distances.append(dist)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 4: `calculate_distances_fast()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances_fast(points_a: np.ndarray, points_b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distances using vectorization.\n",
    "    \n",
    "    Args:\n",
    "        points_a: Array of shape (N, 2) with x, y coordinates\n",
    "        points_b: Array of shape (N, 2) with x, y coordinates\n",
    "    \n",
    "    Returns:\n",
    "        Array of distances\n",
    "    \n",
    "    Hints:\n",
    "        - Use broadcasting: diff = points_a - points_b\n",
    "        - Square: diff**2\n",
    "        - Sum along axis 1: np.sum(..., axis=1)\n",
    "        - Square root: np.sqrt(...)\n",
    "        - Or use np.linalg.norm(points_a - points_b, axis=1)\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test distance calculation\n",
    "n_points = 100_000\n",
    "np.random.seed(42)\n",
    "points_a = np.random.randn(n_points, 2)\n",
    "points_b = np.random.randn(n_points, 2)\n",
    "\n",
    "# Benchmark slow version\n",
    "start = time.perf_counter()\n",
    "result_slow = calculate_distances_slow(points_a, points_b)\n",
    "time_slow = time.perf_counter() - start\n",
    "\n",
    "# Benchmark fast version\n",
    "start = time.perf_counter()\n",
    "result_fast = calculate_distances_fast(points_a, points_b)\n",
    "time_fast = time.perf_counter() - start\n",
    "\n",
    "if result_fast is not None:\n",
    "    match = np.allclose(result_slow, result_fast)\n",
    "    speedup_dist = time_slow / time_fast\n",
    "    print(f\"Distance calculation ({n_points:,} points):\")\n",
    "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
    "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
    "    print(f\"  Speedup: {speedup_dist:.1f}x\")\n",
    "    print(f\"  Results match: {match}\")\n",
    "else:\n",
    "    print(\"TODO: Implement calculate_distances_fast()\")\n",
    "    speedup_dist = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2B: Age Classification\n",
    "\n",
    "Replace conditional loop with `np.select()` or `pd.cut()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original slow implementation\n",
    "def classify_ages_slow(df):\n",
    "    \"\"\"Classify ages using a loop.\"\"\"\n",
    "    categories = []\n",
    "    for age in df['age']:\n",
    "        if age < 18:\n",
    "            categories.append('child')\n",
    "        elif age < 65:\n",
    "            categories.append('adult')\n",
    "        else:\n",
    "            categories.append('senior')\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5: `classify_ages_fast()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ages_fast(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Classify ages using vectorization.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with 'age' column\n",
    "    \n",
    "    Returns:\n",
    "        Array of categories ('child', 'adult', 'senior')\n",
    "    \n",
    "    Hints:\n",
    "        - Use np.select(conditions, choices)\n",
    "        - conditions = [df['age'] < 18, df['age'] < 65, df['age'] >= 65]\n",
    "        - choices = ['child', 'adult', 'senior']\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data with age column\n",
    "n_test = 200_000\n",
    "df_ages = pd.DataFrame({'age': np.random.randint(0, 100, n_test)})\n",
    "\n",
    "# Benchmark\n",
    "start = time.perf_counter()\n",
    "result_slow = classify_ages_slow(df_ages)\n",
    "time_slow = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "result_fast = classify_ages_fast(df_ages)\n",
    "time_fast = time.perf_counter() - start\n",
    "\n",
    "if result_fast is not None:\n",
    "    match = all(s == f for s, f in zip(result_slow, result_fast))\n",
    "    speedup_ages = time_slow / time_fast\n",
    "    print(f\"Age classification ({n_test:,} values):\")\n",
    "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
    "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
    "    print(f\"  Speedup: {speedup_ages:.1f}x\")\n",
    "    print(f\"  Results match: {match}\")\n",
    "else:\n",
    "    print(\"TODO: Implement classify_ages_fast()\")\n",
    "    speedup_ages = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2C: Column Normalization\n",
    "\n",
    "Replace nested loops with broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original slow implementation\n",
    "def normalize_columns_slow(df, columns):\n",
    "    \"\"\"Normalize columns using nested loops.\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        values = df[col].values\n",
    "        mean = sum(values) / len(values)\n",
    "        variance = sum((x - mean)**2 for x in values) / len(values)\n",
    "        std = math.sqrt(variance)\n",
    "        for i in range(len(df)):\n",
    "            df.loc[i, col] = (df.loc[i, col] - mean) / std\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 6: `normalize_columns_fast()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns_fast(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize columns using vectorization.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to normalize\n",
    "        columns: List of columns to normalize\n",
    "    \n",
    "    Returns:\n",
    "        Normalized DataFrame\n",
    "    \n",
    "    Hints:\n",
    "        - Use df[columns].mean() to get means for all columns at once\n",
    "        - Use df[columns].std() for standard deviations\n",
    "        - Broadcasting: (df[columns] - mean) / std\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normalization (use smaller sample due to slow version)\n",
    "n_norm = 10_000\n",
    "df_norm_test = pd.DataFrame({\n",
    "    'a': np.random.randn(n_norm),\n",
    "    'b': np.random.randn(n_norm),\n",
    "    'value': np.random.uniform(0, 1000, n_norm)\n",
    "})\n",
    "columns_to_normalize = ['a', 'b', 'value']\n",
    "\n",
    "# Benchmark\n",
    "start = time.perf_counter()\n",
    "result_slow = normalize_columns_slow(df_norm_test, columns_to_normalize)\n",
    "time_slow = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "result_fast = normalize_columns_fast(df_norm_test, columns_to_normalize)\n",
    "time_fast = time.perf_counter() - start\n",
    "\n",
    "if result_fast is not None:\n",
    "    match = np.allclose(result_slow[columns_to_normalize].values, \n",
    "                        result_fast[columns_to_normalize].values, rtol=1e-5)\n",
    "    speedup_norm = time_slow / time_fast\n",
    "    print(f\"Normalization ({n_norm:,} rows, {len(columns_to_normalize)} columns):\")\n",
    "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
    "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
    "    print(f\"  Speedup: {speedup_norm:.1f}x\")\n",
    "    print(f\"  Results match: {match}\")\n",
    "else:\n",
    "    print(\"TODO: Implement normalize_columns_fast()\")\n",
    "    speedup_norm = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2D: Score Calculation with Clipping\n",
    "\n",
    "Replace loop with vectorized operations and `np.clip()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original slow implementation\n",
    "def calculate_scores_slow(df):\n",
    "    \"\"\"Calculate scores using a loop.\"\"\"\n",
    "    scores = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        score = (row['a'] * 2 + row['b']) / (row['c'] + 1)\n",
    "        if score > 10:\n",
    "            score = 10\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 7: `calculate_scores_fast()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_fast(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate scores using vectorization.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns 'a', 'b', 'c'\n",
    "    \n",
    "    Returns:\n",
    "        Array of scores (clipped to max 10)\n",
    "    \n",
    "    Hints:\n",
    "        - Vectorized formula: (df['a'] * 2 + df['b']) / (df['c'] + 1)\n",
    "        - Use np.clip(scores, None, 10) to clip max value\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score calculation\n",
    "n_scores = 50_000\n",
    "df_score_test = pd.DataFrame({\n",
    "    'a': np.random.randn(n_scores),\n",
    "    'b': np.random.randn(n_scores),\n",
    "    'c': np.random.randint(0, 100, n_scores)\n",
    "})\n",
    "\n",
    "# Benchmark\n",
    "start = time.perf_counter()\n",
    "result_slow = calculate_scores_slow(df_score_test)\n",
    "time_slow = time.perf_counter() - start\n",
    "\n",
    "start = time.perf_counter()\n",
    "result_fast = calculate_scores_fast(df_score_test)\n",
    "time_fast = time.perf_counter() - start\n",
    "\n",
    "if result_fast is not None:\n",
    "    match = np.allclose(result_slow, result_fast)\n",
    "    speedup_scores = time_slow / time_fast\n",
    "    print(f\"Score calculation ({n_scores:,} rows):\")\n",
    "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
    "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
    "    print(f\"  Speedup: {speedup_scores:.1f}x\")\n",
    "    print(f\"  Results match: {match}\")\n",
    "else:\n",
    "    print(\"TODO: Implement calculate_scores_fast()\")\n",
    "    speedup_scores = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insight: The .apply() Trap\n",
    "\n",
    "`.apply()` looks clean but is NOT vectorized:\n",
    "\n",
    "```python\n",
    "# This is SLOW (hidden Python loop):\n",
    "df['result'] = df['x'].apply(lambda x: x * 2)\n",
    "\n",
    "# This is FAST (vectorized):\n",
    "df['result'] = df['x'] * 2\n",
    "```\n",
    "\n",
    "**Benchmark on 10M elements:**\n",
    "| Method | Time | Speedup |\n",
    "|--------|------|--------|\n",
    "| Python loop | 12.5s | 1x |\n",
    "| `.apply()` | 5.8s | 2.2x |\n",
    "| Vectorized | 0.062s | **200x** |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Comprehensive Benchmark (20 min)\n",
    "\n",
    "**Objective**: Quantify the impact of vectorization across different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create large test dataset for benchmarks\n",
    "n_bench = 10_000_000\n",
    "df_bench = pd.DataFrame({\n",
    "    'a': np.random.randn(n_bench),\n",
    "    'b': np.random.randn(n_bench),\n",
    "    'c': np.random.randint(0, 100, n_bench)\n",
    "})\n",
    "print(f\"Benchmark dataset: {n_bench:,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8: `run_vectorization_benchmarks()`\n",
    "\n",
    "Run 5 benchmarks comparing loops vs vectorized operations.\n",
    "\n",
    "**Hints:**\n",
    "- Use a subset (100K rows) for loop versions to avoid waiting too long\n",
    "- Use full dataset for vectorized versions\n",
    "- Scale the loop time: `loop_time * (n_bench / n_subset)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vectorization_benchmarks(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Run 5 benchmarks comparing loops vs vectorized operations.\n",
    "    \n",
    "    Benchmarks:\n",
    "    1. Sum: loop vs .sum()\n",
    "    2. Element-wise multiply: loop vs operator *\n",
    "    3. Filter + transform: loop vs .loc[]\n",
    "    4. .apply() with lambda vs vectorized\n",
    "    5. .apply() with complex function vs NumPy equivalent\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with columns 'a', 'b', 'c'\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with benchmark name -> {\"loop_sec\", \"vec_sec\", \"speedup\"}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    n = len(df)\n",
    "    # Use subset for loop versions\n",
    "    n_subset = 100_000\n",
    "    df_sub = df.head(n_subset)\n",
    "    scale = n / n_subset\n",
    "    \n",
    "    # TODO: Implement 5 benchmarks\n",
    "    #\n",
    "    # Benchmark 1: Sum\n",
    "    #   Loop: total = 0; for x in df_sub['a']: total += x\n",
    "    #   Vectorized: df['a'].sum()\n",
    "    #\n",
    "    # Benchmark 2: Element-wise multiply\n",
    "    #   Loop: result = []; for i in range(len(df_sub)): result.append(df_sub.iloc[i]['a'] * df_sub.iloc[i]['b'])\n",
    "    #   Vectorized: df['a'] * df['b']\n",
    "    #\n",
    "    # Benchmark 3: Filter + transform\n",
    "    #   Loop: result = []; for i in range(len(df_sub)):\n",
    "    #             if df_sub.iloc[i]['c'] > 50: result.append(df_sub.iloc[i]['a'] * 2)\n",
    "    #   Vectorized: df.loc[df['c'] > 50, 'a'] * 2\n",
    "    #\n",
    "    # Benchmark 4: .apply() with lambda vs vectorized\n",
    "    #   Apply: df['a'].apply(lambda x: x * 2 + 1)\n",
    "    #   Vectorized: df['a'] * 2 + 1\n",
    "    #\n",
    "    # Benchmark 5: .apply() with complex function vs NumPy\n",
    "    #   Apply: df.apply(lambda row: (row['a'] * 2 + row['b']) / (row['c'] + 1), axis=1)\n",
    "    #   Vectorized: (df['a'] * 2 + df['b']) / (df['c'] + 1)\n",
    "    #   (Use df_sub for apply, scale time)\n",
    "    #\n",
    "    # For each benchmark, store:\n",
    "    #   results[name] = {'loop_sec': ..., 'vec_sec': ..., 'speedup': ...}\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks\n",
    "print(\"Running vectorization benchmarks...\\n\")\n",
    "\n",
    "vec_benchmarks = run_vectorization_benchmarks(df_bench)\n",
    "\n",
    "if vec_benchmarks:\n",
    "    print(f\"{'Benchmark':<30} {'Loop (s)':>10} {'Vec (s)':>10} {'Speedup':>10}\")\n",
    "    print(\"-\" * 62)\n",
    "    for name, result in vec_benchmarks.items():\n",
    "        print(f\"{name:<30} {result['loop_sec']:>10.4f} {result['vec_sec']:>10.6f} {result['speedup']:>9.0f}x\")\n",
    "else:\n",
    "    print(\"TODO: Implement run_vectorization_benchmarks()\")\n",
    "\n",
    "# Clean up large DataFrame\n",
    "del df_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercise 4: Integrated Pipeline - Format + Vectorization (20 min)\n",
    "\n",
    "**Objective**: Combine efficient formats with vectorized operations in a realistic pipeline.\n",
    "\n",
    "We will compare:\n",
    "- **Naive pipeline**: Read CSV + process with loops\n",
    "- **Optimized pipeline**: Read Parquet (selective + filtered) + vectorized operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 9: `pipeline_naive()`\n",
    "\n",
    "Implement the naive (slow) pipeline.\n",
    "\n",
    "**Hints:**\n",
    "- Read from CSV (full file)\n",
    "- Use a loop to filter and calculate totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_naive() -> dict:\n",
    "    \"\"\"\n",
    "    Naive pipeline: CSV + loops.\n",
    "    \n",
    "    Steps:\n",
    "    1. Read full CSV\n",
    "    2. Loop through rows to find 'Electronica' category\n",
    "    3. Calculate precio * cantidad for matching rows\n",
    "    \n",
    "    Returns:\n",
    "        {\"total\": float, \"count\": int, \"time_sec\": float}\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # start = time.perf_counter()\n",
    "    # df = pd.read_csv(VENTAS_CSV)\n",
    "    # totals = []\n",
    "    # for i in range(len(df)):\n",
    "    #     if df.iloc[i]['categoria'] == 'Electronica':\n",
    "    #         totals.append(df.iloc[i]['precio'] * df.iloc[i]['cantidad'])\n",
    "    # elapsed = time.perf_counter() - start\n",
    "    # return {'total': sum(totals), 'count': len(totals), 'time_sec': round(elapsed, 2)}\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 10: `pipeline_optimized()`\n",
    "\n",
    "Implement the optimized pipeline.\n",
    "\n",
    "**Hints:**\n",
    "- Read from Parquet with `columns=` and `filters=` for predicate pushdown\n",
    "- Use vectorized operations for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_optimized() -> dict:\n",
    "    \"\"\"\n",
    "    Optimized pipeline: Parquet + vectorized.\n",
    "    \n",
    "    Steps:\n",
    "    1. Read Parquet with column selection and predicate pushdown\n",
    "    2. Calculate precio * cantidad using vectorized operations\n",
    "    \n",
    "    Returns:\n",
    "        {\"total\": float, \"count\": int, \"time_sec\": float}\n",
    "    \"\"\"\n",
    "    # TODO: Implement this function\n",
    "    # start = time.perf_counter()\n",
    "    # df = pd.read_parquet(VENTAS_SNAPPY,\n",
    "    #                      columns=['categoria', 'precio', 'cantidad'],\n",
    "    #                      filters=[('categoria', '==', 'Electronica')])\n",
    "    # df['total'] = df['precio'] * df['cantidad']\n",
    "    # elapsed = time.perf_counter() - start\n",
    "    # return {'total': df['total'].sum(), 'count': len(df), 'time_sec': round(elapsed, 2)}\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare pipelines\n",
    "print(\"Running pipeline comparison...\\n\")\n",
    "\n",
    "naive_result = pipeline_naive()\n",
    "optimized_result = pipeline_optimized()\n",
    "\n",
    "if naive_result and optimized_result:\n",
    "    print(f\"Naive pipeline (CSV + loops):\")\n",
    "    print(f\"  Time: {naive_result['time_sec']:.2f} sec\")\n",
    "    print(f\"  Rows processed: {naive_result['count']:,}\")\n",
    "    print(f\"  Total: {naive_result['total']:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nOptimized pipeline (Parquet + vectorized):\")\n",
    "    print(f\"  Time: {optimized_result['time_sec']:.2f} sec\")\n",
    "    print(f\"  Rows processed: {optimized_result['count']:,}\")\n",
    "    print(f\"  Total: {optimized_result['total']:,.2f}\")\n",
    "    \n",
    "    speedup_pipeline = naive_result['time_sec'] / optimized_result['time_sec']\n",
    "    print(f\"\\nSpeedup: {speedup_pipeline:.0f}x\")\n",
    "    print(f\"Results match: {abs(naive_result['total'] - optimized_result['total']) < 0.01}\")\n",
    "else:\n",
    "    print(\"TODO: Implement pipeline_naive() and pipeline_optimized()\")\n",
    "    speedup_pipeline = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where Does the Speedup Come From?\n",
    "\n",
    "| Optimization | Contribution |\n",
    "|--------------|-------------|\n",
    "| Parquet vs CSV (less I/O) | ~3-5x |\n",
    "| Column pruning (3 vs 7 columns) | ~2x |\n",
    "| Predicate pushdown (skip non-matching row groups) | ~2-4x |\n",
    "| Vectorized ops vs loop | ~100-200x |\n",
    "| **Combined** | **~50-200x** |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reflection\n",
    "\n",
    "**Your task:** Write a short reflection (3-5 sentences) answering:\n",
    "\n",
    "1. What was the biggest compression ratio you observed between CSV and Parquet?\n",
    "2. Which vectorization exercise gave you the largest speedup and why?\n",
    "3. How much total speedup did you achieve in the integrated pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your reflection here\n",
    "reflection = \"\"\"\n",
    "Replace this text with your reflection.\n",
    "Think about what you learned about efficient formats and vectorization.\n",
    "What will you do differently in your future data pipelines?\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"Your reflection:\")\n",
    "print(reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "results = {\n",
    "    \"lab\": \"04_formats_vectorization\",\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "    \"exercise_1_formats\": {\n",
    "        \"file_sizes\": format_results if 'format_results' in dir() and format_results else None,\n",
    "        \"read_benchmarks\": read_results if 'read_results' in dir() and read_results else None,\n",
    "    },\n",
    "    \"exercise_2_vectorization\": {\n",
    "        \"distance_speedup\": speedup_dist if 'speedup_dist' in dir() and speedup_dist else None,\n",
    "        \"age_classification_speedup\": speedup_ages if 'speedup_ages' in dir() and speedup_ages else None,\n",
    "        \"normalization_speedup\": speedup_norm if 'speedup_norm' in dir() and speedup_norm else None,\n",
    "        \"scores_speedup\": speedup_scores if 'speedup_scores' in dir() and speedup_scores else None,\n",
    "    },\n",
    "    \"exercise_3_benchmarks\": vec_benchmarks if 'vec_benchmarks' in dir() and vec_benchmarks else None,\n",
    "    \"exercise_4_pipeline\": {\n",
    "        \"naive\": naive_result if 'naive_result' in dir() and naive_result else None,\n",
    "        \"optimized\": optimized_result if 'optimized_result' in dir() and optimized_result else None,\n",
    "        \"speedup\": speedup_pipeline if 'speedup_pipeline' in dir() and speedup_pipeline else None,\n",
    "    },\n",
    "    \"reflection\": reflection,\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Results saved to: {METRICS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lab Complete!\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Format comparison**: Parquet is 3-10x smaller and faster than CSV\n",
    "2. **Compression trade-offs**: Snappy = fast, Zstd = best compression, None = fastest write\n",
    "3. **Feather**: Best for intermediate data (fastest read/write)\n",
    "4. **Vectorization**: NumPy/Pandas operations are 100-200x faster than Python loops\n",
    "5. **The .apply() trap**: It's a hidden loop, not vectorization\n",
    "6. **Combined optimization**: Format + vectorization = massive speedup\n",
    "\n",
    "### Vectorization Cheat Sheet\n",
    "\n",
    "| Pattern | Slow | Fast |\n",
    "|---------|------|------|\n",
    "| Arithmetic | loop + append | `df['a'] * df['b']` |\n",
    "| Conditional | loop + if/else | `np.where()` or `np.select()` |\n",
    "| Binning | loop + if/elif | `pd.cut()` |\n",
    "| Clipping | loop + min/max | `np.clip()` |\n",
    "| Normalization | nested loops | `(df - mean) / std` |\n",
    "| Distance | loop + math.sqrt | `np.linalg.norm()` |\n",
    "\n",
    "### Files to Submit\n",
    "\n",
    "1. `notebooks/lab04_formats_vectorization.ipynb` (this notebook)\n",
    "2. `results/lab04_metrics.json`\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
