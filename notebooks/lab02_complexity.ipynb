{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 02: Complexity\n",
                "\n",
                "In this lab, you will:\n",
                "\n",
                "1. **Measure Time Complexity** â€” Compare O(N) vs O(1) and O(NÂ²) vs O(N log N)\n",
                "2. **Analyze Space Complexity** â€” Compare memory-efficient vs memory-heavy approaches\n",
                "3. **Profile and Optimize** â€” Use profiling tools to find and fix bottlenecks\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“‹ Pre-flight Checklist\n",
                "\n",
                "Before you begin:\n",
                "\n",
                "1. âœ… Run `uv sync --group lab02` to install profiling tools\n",
                "2. âœ… Create a branch: `git checkout -b lab02-complexity`\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Standard library\n",
                "import time\n",
                "import random\n",
                "import json\n",
                "import cProfile\n",
                "import pstats\n",
                "import io\n",
                "import tracemalloc\n",
                "from pathlib import Path\n",
                "from datetime import datetime\n",
                "from collections import Counter\n",
                "\n",
                "# Data science\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Set paths\n",
                "DATA_DIR = Path(\"../data/raw\")\n",
                "RESULTS_DIR = Path(\"../results\")\n",
                "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
                "RESULTS_DIR.mkdir(exist_ok=True)\n",
                "\n",
                "print(\"âœ… Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Exercise 1: Dataset Generation\n",
                "\n",
                "### TODO 1: `generate_user_logs()`\n",
                "\n",
                "Create a 1M row dataset for our experiments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_user_logs(path: Path, n_rows: int = 1_000_000, seed: int = 42) -> dict:\n",
                "    \"\"\"\n",
                "    Generate synthetic user log data and save to CSV.\n",
                "    \n",
                "    TODO: Implement this function\n",
                "    \n",
                "    Args:\n",
                "        path: Path to save the CSV file\n",
                "        n_rows: Number of rows to generate\n",
                "        seed: Random seed for reproducibility\n",
                "    \n",
                "    Returns:\n",
                "        dict with: {\"rows\": int, \"cols\": int, \"size_mb\": float}\n",
                "    \"\"\"\n",
                "    # Step 1: Set random seed with np.random.seed()\n",
                "    # Step 2: Generate user_id (1 to 50000, allows duplicates)\n",
                "    # Step 3: Generate session_id (unique: 0 to n_rows-1)\n",
                "    # Step 4: Generate action (random choice from list)\n",
                "    # Step 5: Generate timestamp (pd.date_range)\n",
                "    # Step 6: Generate value (random floats 0-1000)\n",
                "    # Step 7: Create DataFrame with columns: user_id, session_id, action, timestamp, value\n",
                "    # Step 8: Save to CSV (index=False)\n",
                "    # Step 9: Return metadata dict\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate or load dataset\n",
                "csv_path = DATA_DIR / \"user_logs_1m.csv\"\n",
                "\n",
                "if csv_path.exists():\n",
                "    print(f\"ðŸ“‚ Loading existing dataset from {csv_path}\")\n",
                "    df = pd.read_csv(csv_path)\n",
                "    print(f\"ðŸ“Š Dataset shape: {df.shape}\")\n",
                "else:\n",
                "    print(\"ðŸ”§ Generating new dataset...\")\n",
                "    metadata = generate_user_logs(csv_path)\n",
                "    print(f\"ðŸ’¾ Saved to {csv_path}\")\n",
                "    print(f\"ðŸ“Š Metadata: {metadata}\")\n",
                "    df = pd.read_csv(csv_path)\n",
                "\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Exercise 2: Time Complexity â€” Search & Sort\n",
                "\n",
                "### TODO 2: `benchmark_search()` â€” O(N) vs O(1)\n",
                "\n",
                "Searching in a **list** is O(N) â€” you must check every element.  \n",
                "Searching in a **set** is O(1) â€” hash table lookup."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def benchmark_search(n: int = 1_000_000, n_searches: int = 1000, seed: int = 42) -> dict:\n",
                "    \"\"\"\n",
                "    Compare list search (O(N)) vs set search (O(1)).\n",
                "    \n",
                "    TODO: Implement this function\n",
                "    \n",
                "    Args:\n",
                "        n: Size of the data structure\n",
                "        n_searches: Number of search operations\n",
                "        seed: Random seed\n",
                "    \n",
                "    Returns:\n",
                "        dict with: list_median_ms, set_median_ms, speedup\n",
                "    \"\"\"\n",
                "    # Step 1: Set random seed\n",
                "    # Step 2: Create a list and set of n elements (range(n))\n",
                "    # Step 3: Generate n_searches random keys to search for\n",
                "    # Step 4: Time each search in the list, collect times in ms\n",
                "    # Step 5: Time each search in the set, collect times in ms\n",
                "    # Step 6: Calculate medians and speedup\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Benchmark search\n",
                "print(\"Benchmarking List vs Set search (1M elements, 1000 searches)...\")\n",
                "print(\"This may take a moment...\\n\")\n",
                "\n",
                "search_results = benchmark_search(n=1_000_000, n_searches=1000)\n",
                "\n",
                "if search_results:\n",
                "    print(f\"List median search time: {search_results['list_median_ms']:.4f} ms\")\n",
                "    print(f\"Set median search time:  {search_results['set_median_ms']:.6f} ms\")\n",
                "    print(f\"\\nðŸš€ Set is {search_results['speedup']:.0f}x faster!\")\n",
                "else:\n",
                "    print(\"âš ï¸ benchmark_search() not implemented yet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TODO 3: `bubble_sort()` â€” O(NÂ²) vs O(N log N)\n",
                "\n",
                "Bubble sort is O(NÂ²) â€” nested loops.  \n",
                "Python's Timsort is O(N log N) â€” much more efficient."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def bubble_sort(arr: list) -> list:\n",
                "    \"\"\"\n",
                "    Classic O(NÂ²) bubble sort algorithm.\n",
                "    \n",
                "    TODO: Implement this function\n",
                "    \n",
                "    Args:\n",
                "        arr: List to sort\n",
                "    \n",
                "    Returns:\n",
                "        Sorted list (copy, original unchanged)\n",
                "    \"\"\"\n",
                "    # Step 1: Copy the array (don't modify original)\n",
                "    # Step 2: Get length n\n",
                "    # Step 3: Outer loop: for i in range(n)\n",
                "    # Step 4: Inner loop: for j in range(0, n - i - 1)\n",
                "    #         If arr[j] > arr[j+1], swap them\n",
                "    # Step 5: Return sorted array\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Compare sorting algorithms\n",
                "test_sizes = [100, 500, 1000, 2000, 5000]\n",
                "\n",
                "print(\"Comparing Bubble Sort vs Python Sort:\\n\")\n",
                "print(f\"{'N':>6} | {'Bubble (ms)':>12} | {'Python (ms)':>12} | {'Speedup':>10}\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for n in test_sizes:\n",
                "    data = list(range(n))\n",
                "    random.shuffle(data)\n",
                "    \n",
                "    # Time bubble sort\n",
                "    start = time.perf_counter()\n",
                "    result = bubble_sort(data)\n",
                "    bubble_time = (time.perf_counter() - start) * 1000\n",
                "    \n",
                "    if result is None:\n",
                "        print(f\"âš ï¸ bubble_sort() not implemented yet\")\n",
                "        break\n",
                "    \n",
                "    # Time Python sort\n",
                "    start = time.perf_counter()\n",
                "    sorted(data)\n",
                "    python_time = (time.perf_counter() - start) * 1000\n",
                "    \n",
                "    speedup = bubble_time / python_time if python_time > 0 else 0\n",
                "    print(f\"{n:>6} | {bubble_time:>12.2f} | {python_time:>12.4f} | {speedup:>10.0f}x\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Key Insight\n",
                "\n",
                "As N grows:\n",
                "- Bubble sort (O(NÂ²)) gets **quadratically** slower\n",
                "- Python sort (O(N log N)) scales much better\n",
                "\n",
                "At N=5000, the difference is **100x or more**!\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 3: Space Complexity â€” Memory Trade-offs\n",
                "\n",
                "Time isn't everything â€” sometimes **memory** is the bottleneck.\n",
                "\n",
                "### TODO 4: `find_duplicates_set()` â€” O(N) time, O(N) space\n",
                "### TODO 5: `find_duplicates_inplace()` â€” O(N log N) time, O(1) space"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_duplicates_set(data: list) -> list:\n",
                "    \"\"\"\n",
                "    Find duplicates using a set. O(N) time, O(N) space.\n",
                "    \n",
                "    TODO: Implement this function\n",
                "    \n",
                "    Args:\n",
                "        data: List of values (may contain duplicates)\n",
                "    \n",
                "    Returns:\n",
                "        List of values that appear more than once\n",
                "    \"\"\"\n",
                "    # Step 1: Create a set to track seen items\n",
                "    # Step 2: Create a set to track duplicates\n",
                "    # Step 3: Iterate through data\n",
                "    #   - If item in seen, add to duplicates\n",
                "    #   - Else add to seen\n",
                "    # Step 4: Return list of duplicates\n",
                "    pass\n",
                "\n",
                "\n",
                "def find_duplicates_inplace(data: list) -> list:\n",
                "    \"\"\"\n",
                "    Find duplicates by sorting first. O(N log N) time, O(1) extra space.\n",
                "    \n",
                "    TODO: Implement this function\n",
                "    \n",
                "    WARNING: This modifies the input list!\n",
                "    \n",
                "    Args:\n",
                "        data: List of values (WILL BE MODIFIED - sorted in place)\n",
                "    \n",
                "    Returns:\n",
                "        List of values that appear more than once\n",
                "    \"\"\"\n",
                "    # Step 1: Sort the list in-place with data.sort()\n",
                "    # Step 2: Create a set for duplicates\n",
                "    # Step 3: Iterate through sorted list\n",
                "    #   - If current == previous, it's a duplicate\n",
                "    # Step 4: Return list of duplicates\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def measure_memory(func, *args):\n",
                "    \"\"\"Measure peak memory usage of a function.\"\"\"\n",
                "    tracemalloc.start()\n",
                "    result = func(*args)\n",
                "    current, peak = tracemalloc.get_traced_memory()\n",
                "    tracemalloc.stop()\n",
                "    return result, peak / 1024 / 1024  # Convert to MB\n",
                "\n",
                "# Compare approaches\n",
                "print(\"Comparing Space Complexity:\\n\")\n",
                "\n",
                "# Generate test data with known duplicates\n",
                "test_data = list(range(100_000)) + list(range(50_000))  # 50k duplicates\n",
                "random.shuffle(test_data)\n",
                "\n",
                "# Measure set-based approach\n",
                "data_copy1 = test_data.copy()\n",
                "start = time.perf_counter()\n",
                "result1, mem1 = measure_memory(find_duplicates_set, data_copy1)\n",
                "time1 = (time.perf_counter() - start) * 1000\n",
                "\n",
                "# Measure in-place approach\n",
                "data_copy2 = test_data.copy()\n",
                "start = time.perf_counter()\n",
                "result2, mem2 = measure_memory(find_duplicates_inplace, data_copy2)\n",
                "time2 = (time.perf_counter() - start) * 1000\n",
                "\n",
                "if result1 and result2:\n",
                "    print(f\"{'Method':<20} | {'Time (ms)':<12} | {'Peak Memory (MB)':<18}\")\n",
                "    print(\"-\" * 55)\n",
                "    print(f\"{'Set-based':<20} | {time1:<12.2f} | {mem1:<18.2f}\")\n",
                "    print(f\"{'Sort in-place':<20} | {time2:<12.2f} | {mem2:<18.2f}\")\n",
                "    print(f\"\\nðŸ” Duplicates found: {len(result1)}\")\n",
                "else:\n",
                "    print(\"âš ï¸ Functions not implemented yet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ Key Insight\n",
                "\n",
                "| Approach | Time | Space | Best When... |\n",
                "|----------|------|-------|--------------|\n",
                "| Set-based | O(N) | O(N) | Memory is plentiful, speed is critical |\n",
                "| Sort in-place | O(N log N) | O(1) | Memory is limited, data can be modified |\n",
                "\n",
                "This is a classic **time-space trade-off**!\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 4: Profiling Bottlenecks\n",
                "\n",
                "We provide a deliberately terrible O(NÂ²) function. Your job:\n",
                "\n",
                "1. Profile it to understand WHERE the time goes\n",
                "2. Optimize it in the next exercise\n",
                "\n",
                "### The Slow Function (Provided)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_duplicates_slow(data: list) -> list:\n",
                "    \"\"\"O(NÂ²) nested loop - intentionally terrible!\"\"\"\n",
                "    duplicates = []\n",
                "    for i in range(len(data)):\n",
                "        for j in range(i + 1, len(data)):\n",
                "            if data[i] == data[j] and data[i] not in duplicates:\n",
                "                duplicates.append(data[i])\n",
                "    return duplicates\n",
                "\n",
                "# Test on small sample\n",
                "sample = df[\"user_id\"].head(1000).tolist()\n",
                "\n",
                "start = time.perf_counter()\n",
                "result = find_duplicates_slow(sample)\n",
                "elapsed = time.perf_counter() - start\n",
                "\n",
                "print(f\"Found {len(result)} duplicates in {elapsed:.3f} seconds\")\n",
                "print(f\"\\nâš ï¸ This is SLOW! At 10k rows it would take ~{elapsed * 100:.0f} seconds!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TODO 6: `profile_function()` â€” cProfile Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def profile_function(fn, *args, **kwargs) -> tuple:\n",
                "    \"\"\"\n",
                "    Profile a function using cProfile.\n",
                "    \n",
                "    TODO: Implement this function\n",
                "    \n",
                "    Args:\n",
                "        fn: Function to profile\n",
                "        *args, **kwargs: Arguments to pass to function\n",
                "    \n",
                "    Returns:\n",
                "        Tuple of (function_result, profile_stats_string)\n",
                "    \"\"\"\n",
                "    # Step 1: Create a cProfile.Profile() object\n",
                "    # Step 2: Enable profiling with profiler.enable()\n",
                "    # Step 3: Call the function: result = fn(*args, **kwargs)\n",
                "    # Step 4: Disable profiling with profiler.disable()\n",
                "    # Step 5: Create pstats.Stats from profiler\n",
                "    # Step 6: Sort by cumulative time with stats.sort_stats('cumulative')\n",
                "    # Step 7: Capture stats output to a StringIO\n",
                "    # Step 8: Return (result, stats_string)\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Profile the slow function\n",
                "sample = df[\"user_id\"].head(2000).tolist()\n",
                "\n",
                "print(\"Profiling find_duplicates_slow()...\\n\")\n",
                "\n",
                "profile_result = profile_function(find_duplicates_slow, sample)\n",
                "\n",
                "if profile_result:\n",
                "    result, stats = profile_result\n",
                "    print(stats[:2000])  # Print first 2000 chars\n",
                "else:\n",
                "    print(\"âš ï¸ profile_function() not implemented yet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Flamegraph with py-spy (Demonstration)\n",
                "\n",
                "Flamegraphs give you a visual representation of where time is spent.\n",
                "\n",
                "Run the cell below to generate a script, then run py-spy from terminal."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate a standalone script for py-spy profiling\n",
                "flamegraph_script = '''\n",
                "\"\"\"Script for py-spy flamegraph profiling.\"\"\"\n",
                "import pandas as pd\n",
                "from pathlib import Path\n",
                "\n",
                "def find_duplicates_slow(data: list) -> list:\n",
                "    \"\"\"O(NÂ²) nested loop - intentionally terrible!\"\"\"\n",
                "    duplicates = []\n",
                "    for i in range(len(data)):\n",
                "        for j in range(i + 1, len(data)):\n",
                "            if data[i] == data[j] and data[i] not in duplicates:\n",
                "                duplicates.append(data[i])\n",
                "    return duplicates\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # Load sample data\n",
                "    df = pd.read_csv(\"data/raw/user_logs_1m.csv\", nrows=3000)\n",
                "    data = df[\"user_id\"].tolist()\n",
                "    \n",
                "    print(f\"Processing {len(data)} items...\")\n",
                "    result = find_duplicates_slow(data)\n",
                "    print(f\"Found {len(result)} duplicates\")\n",
                "'''\n",
                "\n",
                "# Save script\n",
                "script_path = Path(\"flamegraph_profile.py\")\n",
                "script_path.write_text(flamegraph_script.strip())\n",
                "\n",
                "print(f\"âœ… Script saved to: {script_path.absolute()}\")\n",
                "print(\"\\nðŸ“‹ Run these commands from the project root:\")\n",
                "print(\"\\n  # Generate flamegraph:\")\n",
                "print(\"  py-spy record -o flamegraph.svg -- python flamegraph_profile.py\")\n",
                "print(\"\\n  # Open in browser:\")\n",
                "print(\"  open flamegraph.svg\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Line-by-Line Profiling (Demonstration)\n",
                "\n",
                "Use `line_profiler` to see exactly which lines are slow."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def profile_line_by_line(fn, *args, **kwargs):\n",
                "    \"\"\"\n",
                "    Profile a function line by line.\n",
                "    \n",
                "    Requires: line_profiler (included in lab02 group)\n",
                "    \"\"\"\n",
                "    try:\n",
                "        from line_profiler import LineProfiler\n",
                "    except ImportError:\n",
                "        print(\"âš ï¸ line_profiler not installed. Run: uv sync --group lab02\")\n",
                "        return fn(*args, **kwargs), \"line_profiler not available\"\n",
                "    \n",
                "    profiler = LineProfiler()\n",
                "    profiler.add_function(fn)\n",
                "    \n",
                "    wrapper = profiler(fn)\n",
                "    result = wrapper(*args, **kwargs)\n",
                "    \n",
                "    # Capture output\n",
                "    output = io.StringIO()\n",
                "    profiler.print_stats(stream=output)\n",
                "    \n",
                "    return result, output.getvalue()\n",
                "\n",
                "# Profile line by line\n",
                "sample = df[\"user_id\"].head(1000).tolist()\n",
                "\n",
                "print(\"Line-by-line profile of find_duplicates_slow():\\n\")\n",
                "result, stats = profile_line_by_line(find_duplicates_slow, sample)\n",
                "print(stats)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ’¡ What Did You Find?\n",
                "\n",
                "The profiler should show:\n",
                "\n",
                "1. **The nested loop** (`for j in range...`) takes most time\n",
                "2. **The `in duplicates` check** is also O(N) on a list!\n",
                "\n",
                "Both are O(N) operations inside an O(N) loop = O(NÂ²) total!\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exercise 5: The 10x Challenge ðŸ†\n",
                "\n",
                "### TODO 7: `find_duplicates_fast()`\n",
                "\n",
                "Your goal: Make this **at least 10x faster** than the slow version."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def find_duplicates_fast(data: list) -> list:\n",
                "    \"\"\"\n",
                "    Find duplicates efficiently. Target: O(N) time.\n",
                "    \n",
                "    TODO: Implement this function\n",
                "    \n",
                "    Hint: Use collections.Counter!\n",
                "    \n",
                "    Args:\n",
                "        data: List of values\n",
                "    \n",
                "    Returns:\n",
                "        List of values that appear more than once\n",
                "    \"\"\"\n",
                "    # Strategy: Use Counter to count occurrences in O(N)\n",
                "    # Step 1: counts = Counter(data)\n",
                "    # Step 2: Filter for items with count > 1\n",
                "    # Step 3: Return as list\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST: Compare slow vs fast\n",
                "sample = df[\"user_id\"].head(5000).tolist()\n",
                "\n",
                "# Time slow version\n",
                "start = time.perf_counter()\n",
                "slow_result = find_duplicates_slow(sample)\n",
                "slow_time = time.perf_counter() - start\n",
                "\n",
                "# Time fast version\n",
                "start = time.perf_counter()\n",
                "fast_result = find_duplicates_fast(sample)\n",
                "fast_time = time.perf_counter() - start\n",
                "\n",
                "if fast_result:\n",
                "    speedup = slow_time / fast_time if fast_time > 0 else 0\n",
                "    \n",
                "    print(f\"Slow version: {slow_time:.3f}s ({len(slow_result)} duplicates)\")\n",
                "    print(f\"Fast version: {fast_time:.6f}s ({len(fast_result)} duplicates)\")\n",
                "    print(f\"\\nðŸš€ Speedup: {speedup:.0f}x\")\n",
                "    \n",
                "    if speedup >= 10:\n",
                "        print(\"\\nðŸ† CHALLENGE COMPLETE! You achieved 10x+ speedup!\")\n",
                "    else:\n",
                "        print(f\"\\nâš ï¸ Keep optimizing! Need {10/speedup:.1f}x more improvement.\")\n",
                "else:\n",
                "    print(\"âš ï¸ find_duplicates_fast() not implemented yet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Save Results & Reflection\n",
                "\n",
                "Save your benchmark results for later comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect all results\n",
                "results = {\n",
                "    \"timestamp\": datetime.now().isoformat(),\n",
                "    \"exercise_1\": {\n",
                "        \"description\": \"Dataset generation\",\n",
                "        \"completed\": csv_path.exists()\n",
                "    },\n",
                "    \"exercise_2\": {\n",
                "        \"search_benchmark\": search_results if 'search_results' in dir() and search_results else None,\n",
                "        \"description\": \"Time complexity - search & sort\"\n",
                "    },\n",
                "    \"exercise_3\": {\n",
                "        \"set_based_memory_mb\": mem1 if 'mem1' in dir() else None,\n",
                "        \"inplace_memory_mb\": mem2 if 'mem2' in dir() else None,\n",
                "        \"description\": \"Space complexity comparison\"\n",
                "    },\n",
                "    \"exercise_4\": {\n",
                "        \"profiling_completed\": 'profile_result' in dir() and profile_result is not None,\n",
                "        \"description\": \"Profiling with cProfile\"\n",
                "    },\n",
                "    \"exercise_5\": {\n",
                "        \"slow_time_sec\": slow_time if 'slow_time' in dir() else None,\n",
                "        \"fast_time_sec\": fast_time if 'fast_time' in dir() else None,\n",
                "        \"speedup\": speedup if 'speedup' in dir() else None,\n",
                "        \"challenge_passed\": speedup >= 10 if 'speedup' in dir() else False,\n",
                "        \"description\": \"Optimization challenge\"\n",
                "    }\n",
                "}\n",
                "\n",
                "# Save to file\n",
                "results_path = RESULTS_DIR / \"lab02_metrics.json\"\n",
                "with open(results_path, \"w\") as f:\n",
                "    json.dump(results, f, indent=2, default=str)\n",
                "\n",
                "print(f\"âœ… Results saved to {results_path}\")\n",
                "print(json.dumps(results, indent=2, default=str))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸŽ¯ Summary\n",
                "\n",
                "In this lab, you learned:\n",
                "\n",
                "### Time Complexity\n",
                "- **O(1)** hash lookups are MUCH faster than **O(N)** list searches\n",
                "- **O(N log N)** sorting beats **O(NÂ²)** by orders of magnitude\n",
                "\n",
                "### Space Complexity\n",
                "- Using extra memory (sets/dicts) can speed things up\n",
                "- In-place algorithms save memory at the cost of time\n",
                "- **Trade-offs are everywhere!**\n",
                "\n",
                "### Profiling\n",
                "- **cProfile** shows which functions take the most time\n",
                "- **py-spy** creates visual flamegraphs\n",
                "- **line_profiler** shows exactly which lines are slow\n",
                "\n",
                "### Optimization\n",
                "- Choosing the right data structure can give **1000x+ speedups**\n",
                "- Always **measure** before optimizing\n",
                "- **Algorithms > Hardware** â€” a better algorithm on a laptop beats a bad algorithm on a supercomputer!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
