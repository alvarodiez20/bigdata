{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 01: Environment Setup and Basic I/O Benchmarking\n",
        "\n",
        "**Course:** Big Data\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ‘¤ Student Information\n",
        "\n",
        "**Name:** `[Your Full Name Here]`\n",
        "\n",
        "**Date:** `[Date of Submission]`\n",
        "\n",
        "---\n",
        "\n",
        "**Goal:** Setup and verify your environment works. Compare CSV vs Parquet performance.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. **Fill in your information above** before starting the lab\n",
        "2. Read each cell carefully before running it\n",
        "3. Implement the **TODO functions** when you see them\n",
        "4. Run cells **from top to bottom** (Shift+Enter)\n",
        "5. Check that output makes sense after each cell\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ðŸ“š Libraries Used in This Lab\n",
        "\n",
        "This lab uses several essential Python libraries for data science and big data:\n",
        "\n",
        "### Core Libraries\n",
        "\n",
        "- **`pandas`** - Data manipulation and analysis\n",
        "  - Used for: Reading/writing CSV and Parquet files, creating DataFrames\n",
        "  - [Documentation](https://pandas.pydata.org/docs/)\n",
        "\n",
        "- **`numpy`** - Numerical computing\n",
        "  - Used for: Generating random data, calculating statistics (median)\n",
        "  - [Documentation](https://numpy.org/doc/)\n",
        "\n",
        "- **`pathlib.Path`** - Modern file path handling\n",
        "  - Used for: Cross-platform file paths, directory creation\n",
        "  - [Documentation](https://docs.python.org/3/library/pathlib.html)\n",
        "\n",
        "- **`time`** - Time measurement\n",
        "  - Used for: Precise performance benchmarking\n",
        "  - [Documentation](https://docs.python.org/3/library/time.html)\n",
        "\n",
        "- **`json`** - JSON serialization\n",
        "  - Used for: Saving results in a structured format\n",
        "  - [Documentation](https://docs.python.org/3/library/json.html)\n",
        "\n",
        "### Why These Libraries?\n",
        "\n",
        "- **pandas**: Industry standard for data manipulation in Python\n",
        "- **numpy**: Foundation for numerical computing, used by pandas internally\n",
        "- **Parquet**: Columnar storage format - faster and more efficient than CSV for big data\n",
        "- **pathlib**: Modern, object-oriented approach to file paths (better than `os.path`)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ’¡ Quick Tips\n",
        "\n",
        "- **Read the docstrings carefully** - They tell you exactly what each function should do\n",
        "- **Run test cells immediately** - Verify each function works before moving on\n",
        "- **Use print statements** - Debug by printing intermediate values\n",
        "- **Check the error messages** - They often tell you exactly what's wrong\n",
        "\n",
        "**Need help?** Check out:\n",
        "- [Tips & Guidance](../docs/labs/lab01_tips.md) - Detailed hints for each TODO\n",
        "- [Quick Reference](../docs/labs/lab01_quick_reference.md) - Cheat sheet with essential functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Version Check\n",
        "\n",
        "Let's verify all required libraries are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ All imports successful!\n",
            "Pandas version: 2.3.3\n",
            "NumPy version: 2.4.0\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"âœ“ All imports successful!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Paths\n",
        "\n",
        "We'll use **relative paths** so the notebook works on any machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paths defined:\n",
            "  CSV: ../data/raw/synthetic.csv\n",
            "  Parquet: ../data/processed/synthetic.parquet\n",
            "  Metrics: ../results/lab01_metrics.json\n"
          ]
        }
      ],
      "source": [
        "# Base directories\n",
        "DATA_RAW = Path(\"../data/raw\")\n",
        "DATA_PROCESSED = Path(\"../data/processed\")\n",
        "RESULTS_DIR = Path(\"../results\")\n",
        "\n",
        "# File paths\n",
        "CSV_PATH = DATA_RAW / \"synthetic.csv\"\n",
        "PARQUET_PATH = DATA_PROCESSED / \"synthetic.parquet\"\n",
        "METRICS_PATH = RESULTS_DIR / \"lab01_metrics.json\"\n",
        "\n",
        "print(\"Paths defined:\")\n",
        "print(f\"  CSV: {CSV_PATH}\")\n",
        "print(f\"  Parquet: {PARQUET_PATH}\")\n",
        "print(f\"  Metrics: {METRICS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. TODO Functions\n",
        "\n",
        "**Your task:** Implement these 7 functions. Read the docstring carefully!\n",
        "\n",
        "After implementing each function, run the test cell below it to verify it works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO 1: `ensure_dir()`\n",
        "\n",
        "Create a directory if it doesn't exist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ’¡ Hint:** Use `path.mkdir()` with `parents=True` (create parent directories) and `exist_ok=True` (don't error if exists).\n",
        "\n",
        "**Need more help?** See [TODO 1 detailed tips](../docs/labs/lab01_tips.md#todo-1-ensure_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ensure_dir(path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Create a directory if it doesn't exist.\n",
        "    \n",
        "    Args:\n",
        "        path: Path to the directory\n",
        "    \n",
        "    Example:\n",
        "        ensure_dir(Path(\"data/raw\"))\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hint: Use path.mkdir() with appropriate arguments\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: ensure_dir()\n",
        "ensure_dir(DATA_RAW)\n",
        "ensure_dir(DATA_PROCESSED)\n",
        "ensure_dir(RESULTS_DIR)\n",
        "\n",
        "assert DATA_RAW.exists(), \"data/raw should exist\"\n",
        "assert DATA_PROCESSED.exists(), \"data/processed should exist\"\n",
        "assert RESULTS_DIR.exists(), \"results should exist\"\n",
        "print(\"âœ“ ensure_dir() works correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO 2: `write_synthetic_csv()`\n",
        "\n",
        "Generate a simple synthetic dataset and save it as CSV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ’¡ Key Steps:**\n",
        "1. Set random seed with `np.random.seed(seed)`\n",
        "2. Generate timestamps with `pd.date_range()`\n",
        "3. Generate random integers with `np.random.randint()`\n",
        "4. Generate random floats with `np.random.uniform()`\n",
        "5. Generate random categories with `np.random.choice()`\n",
        "6. Create DataFrame with `pd.DataFrame({...})`\n",
        "7. Save with `df.to_csv(csv_path, index=False)`\n",
        "8. Get file size with `csv_path.stat().st_size`\n",
        "\n",
        "**Need more help?** See [TODO 2 detailed tips](../docs/labs/lab01_tips.md#todo-2-write_synthetic_csv)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_synthetic_csv(csv_path: Path, n_rows: int = 200_000, seed: int = 0) -> dict:\n",
        "    \"\"\"\n",
        "    Generate a synthetic dataset and save as CSV.\n",
        "    \n",
        "    Args:\n",
        "        csv_path: Where to save the CSV\n",
        "        n_rows: Number of rows to generate\n",
        "        seed: Random seed for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with metadata: {\"rows\": int, \"cols\": int, \"size_bytes\": int}\n",
        "    \n",
        "    The dataset should have these columns:\n",
        "        - timestamp: datetime strings (e.g., \"2024-01-01 12:00:00\")\n",
        "        - user_id: random integers from 1 to 10000\n",
        "        - value: random floats from 0 to 100\n",
        "        - category: random choice from [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hints:\n",
        "    # 1. Use np.random.seed(seed) for reproducibility\n",
        "    # 2. Create a DataFrame with the 4 columns described above\n",
        "    # 3. Save with df.to_csv(csv_path, index=False)\n",
        "    # 4. Get file size with csv_path.stat().st_size\n",
        "    # 5. Return a dict with rows, cols, and size_bytes\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: write_synthetic_csv()\n",
        "if not CSV_PATH.exists():\n",
        "    metadata = write_synthetic_csv(CSV_PATH, n_rows=200_000, seed=42)\n",
        "    print(f\"Generated CSV: {metadata}\")\n",
        "    assert metadata[\"rows\"] == 200_000, \"Should have 200k rows\"\n",
        "    assert metadata[\"cols\"] == 4, \"Should have 4 columns\"\n",
        "    assert metadata[\"size_bytes\"] > 0, \"File size should be positive\"\n",
        "    print(\"âœ“ write_synthetic_csv() works correctly!\")\n",
        "else:\n",
        "    print(f\"CSV already exists, skipping generation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO 3: `time_it()`\n",
        "\n",
        "Measure how long a function takes to run (repeat multiple times)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ’¡ Key Steps:**\n",
        "1. Create empty list: `times = []`\n",
        "2. Loop `repeats` times\n",
        "3. Inside loop: record start time, call `fn()`, record end time\n",
        "4. Append elapsed time to list\n",
        "5. Calculate median with `np.median(times)`\n",
        "6. Return dict with `\"runs_sec\"` and `\"median_sec\"`\n",
        "\n",
        "**Why median?** It's less affected by outliers than mean - gives you the \"typical\" performance.\n",
        "\n",
        "**Need more help?** See [TODO 3 detailed tips](../docs/labs/lab01_tips.md#todo-3-time_it)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def time_it(fn, repeats: int = 3) -> dict:\n",
        "    \"\"\"\n",
        "    Time a function by running it multiple times.\n",
        "    \n",
        "    Args:\n",
        "        fn: A callable (function with no arguments)\n",
        "        repeats: How many times to run the function\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with:\n",
        "            - \"runs_sec\": list of times (in seconds) for each run\n",
        "            - \"median_sec\": median time\n",
        "    \n",
        "    Example:\n",
        "        result = time_it(lambda: pd.read_csv(\"data.csv\"), repeats=3)\n",
        "        print(result[\"median_sec\"])\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hints:\n",
        "    # 1. Create an empty list to store times\n",
        "    # 2. Loop 'repeats' times:\n",
        "    #    - Record start time with time.perf_counter()\n",
        "    #    - Call fn()\n",
        "    #    - Record end time\n",
        "    #    - Append (end - start) to the list\n",
        "    # 3. Calculate median using np.median()\n",
        "    # 4. Return a dict with \"runs_sec\" and \"median_sec\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: time_it()\n",
        "result = time_it(lambda: time.sleep(0.01), repeats=3)\n",
        "assert len(result[\"runs_sec\"]) == 3, \"Should have 3 runs\"\n",
        "assert result[\"median_sec\"] > 0, \"Median should be positive\"\n",
        "print(f\"Test result: {result}\")\n",
        "print(\"âœ“ time_it() works correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO 4: `read_csv_once()`\n",
        "\n",
        "Read a CSV file and return its shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ’¡ Hint:** Use `pd.read_csv(csv_path)` to read the file, then return `df.shape` (which is a tuple of `(rows, cols)`).\n",
        "\n",
        "**Need more help?** See [TODO 4 detailed tips](../docs/labs/lab01_tips.md#todo-4-read_csv_once)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_csv_once(csv_path: Path) -> tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Read a CSV file and return its shape.\n",
        "    \n",
        "    Args:\n",
        "        csv_path: Path to the CSV file\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (n_rows, n_cols)\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hints:\n",
        "    # 1. Use pd.read_csv(csv_path)\n",
        "    # 2. Get the shape with df.shape\n",
        "    # 3. Return the shape as a tuple\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: read_csv_once()\n",
        "rows, cols = read_csv_once(CSV_PATH)\n",
        "assert rows == 200_000, \"Should have 200k rows\"\n",
        "assert cols == 4, \"Should have 4 columns\"\n",
        "print(f\"CSV shape: {rows} rows Ã— {cols} cols\")\n",
        "print(\"âœ“ read_csv_once() works correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO 5: `write_parquet()`\n",
        "\n",
        "Convert a CSV file to Parquet format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ’¡ Key Steps:**\n",
        "1. Read CSV with `pd.read_csv(csv_path)`\n",
        "2. Write Parquet with `df.to_parquet(parquet_path, index=False)`\n",
        "3. Get file size with `parquet_path.stat().st_size`\n",
        "4. Return dict with metadata\n",
        "\n",
        "**What is Parquet?** A columnar storage format that's faster and more efficient than CSV. You'll see the difference in the benchmark!\n",
        "\n",
        "**Need more help?** See [TODO 5 detailed tips](../docs/labs/lab01_tips.md#todo-5-write_parquet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def write_parquet(csv_path: Path, parquet_path: Path) -> dict:\n",
        "    \"\"\"\n",
        "    Read a CSV and write it as Parquet.\n",
        "    \n",
        "    Args:\n",
        "        csv_path: Input CSV file\n",
        "        parquet_path: Output Parquet file\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with: {\"parquet_size_bytes\": int, \"rows\": int, \"cols\": int}\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hints:\n",
        "    # 1. Read the CSV with pd.read_csv()\n",
        "    # 2. Write to Parquet with df.to_parquet(parquet_path, index=False)\n",
        "    # 3. Get file size with parquet_path.stat().st_size\n",
        "    # 4. Return metadata dict\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: write_parquet()\n",
        "if not PARQUET_PATH.exists():\n",
        "    metadata = write_parquet(CSV_PATH, PARQUET_PATH)\n",
        "    print(f\"Generated Parquet: {metadata}\")\n",
        "    assert metadata[\"rows\"] == 200_000, \"Should have 200k rows\"\n",
        "    assert metadata[\"cols\"] == 4, \"Should have 4 columns\"\n",
        "    assert metadata[\"parquet_size_bytes\"] > 0, \"File size should be positive\"\n",
        "    print(\"âœ“ write_parquet() works correctly!\")\n",
        "else:\n",
        "    print(f\"Parquet already exists, skipping conversion\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO 6: `read_parquet_once()`\n",
        "\n",
        "Read a Parquet file and return its shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ’¡ Hint:** Same as `read_csv_once()`, but use `pd.read_parquet(parquet_path)` instead.\n",
        "\n",
        "**Need more help?** See [TODO 6 detailed tips](../docs/labs/lab01_tips.md#todo-6-read_parquet_once)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_parquet_once(parquet_path: Path) -> tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Read a Parquet file and return its shape.\n",
        "    \n",
        "    Args:\n",
        "        parquet_path: Path to the Parquet file\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (n_rows, n_cols)\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hints:\n",
        "    # 1. Use pd.read_parquet(parquet_path)\n",
        "    # 2. Get the shape with df.shape\n",
        "    # 3. Return the shape as a tuple\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: read_parquet_once()\n",
        "rows, cols = read_parquet_once(PARQUET_PATH)\n",
        "assert rows == 200_000, \"Should have 200k rows\"\n",
        "assert cols == 4, \"Should have 4 columns\"\n",
        "print(f\"Parquet shape: {rows} rows Ã— {cols} cols\")\n",
        "print(\"âœ“ read_parquet_once() works correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TODO 7: `save_json()`\n",
        "\n",
        "Save a Python dictionary as a pretty-printed JSON file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**ðŸ’¡ Key Steps:**\n",
        "1. Open file with `with open(path, \"w\") as f:`\n",
        "2. Write JSON with `json.dump(obj, f, indent=2)`\n",
        "\n",
        "**Why `indent=2`?** Makes the JSON human-readable with nice formatting.\n",
        "\n",
        "**Need more help?** See [TODO 7 detailed tips](../docs/labs/lab01_tips.md#todo-7-save_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_json(obj: dict, path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Save a dictionary as JSON.\n",
        "    \n",
        "    Args:\n",
        "        obj: Dictionary to save\n",
        "        path: Output JSON file path\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hints:\n",
        "    # 1. Open the file with open(path, \"w\") as f\n",
        "    # 2. Use json.dump(obj, f, indent=2) to write pretty JSON\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TEST: save_json()\n",
        "test_path = RESULTS_DIR / \"test.json\"\n",
        "save_json({\"test\": \"value\"}, test_path)\n",
        "assert test_path.exists(), \"JSON file should exist\"\n",
        "with open(test_path) as f:\n",
        "    loaded = json.load(f)\n",
        "assert loaded[\"test\"] == \"value\", \"JSON should be saved correctly\"\n",
        "test_path.unlink()  # Clean up\n",
        "print(\"âœ“ save_json() works correctly!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Benchmark CSV Read Performance\n",
        "\n",
        "Now let's measure how long it takes to read the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Benchmarking CSV read (3 repeats)...\")\n",
        "csv_result = time_it(lambda: read_csv_once(CSV_PATH), repeats=3)\n",
        "\n",
        "print(f\"Run times: {csv_result['runs_sec']}\")\n",
        "print(f\"Median: {csv_result['median_sec']:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Benchmark Parquet Read Performance\n",
        "\n",
        "Same thing, but for the Parquet file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Benchmarking Parquet read (3 repeats)...\")\n",
        "parquet_result = time_it(lambda: read_parquet_once(PARQUET_PATH), repeats=3)\n",
        "\n",
        "print(f\"Run times: {parquet_result['runs_sec']}\")\n",
        "print(f\"Median: {parquet_result['median_sec']:.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compare Results\n",
        "\n",
        "Let's calculate the speedup and compare file sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "csv_size = CSV_PATH.stat().st_size\n",
        "parquet_size = PARQUET_PATH.stat().st_size\n",
        "\n",
        "speedup = csv_result[\"median_sec\"] / parquet_result[\"median_sec\"]\n",
        "size_ratio = csv_size / parquet_size\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "print(f\"CSV file size:     {csv_size / 1_000_000:.2f} MB\")\n",
        "print(f\"Parquet file size: {parquet_size / 1_000_000:.2f} MB\")\n",
        "print(f\"Size ratio:        {size_ratio:.2f}x (CSV is {size_ratio:.2f}x larger)\")\n",
        "print()\n",
        "print(f\"CSV median read time:     {csv_result['median_sec']:.4f} sec\")\n",
        "print(f\"Parquet median read time: {parquet_result['median_sec']:.4f} sec\")\n",
        "print(f\"Speedup: {speedup:.2f}x (Parquet is {speedup:.2f}x faster)\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Reflection\n",
        "\n",
        "**Your task:** Write a short reflection (3 lines) answering these questions:\n",
        "\n",
        "1. What surprised you about the performance difference?\n",
        "2. Why do you think Parquet is faster/smaller?\n",
        "\n",
        "Edit the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Write your reflection here (replace the placeholder text)\n",
        "reflection = \"\"\"\n",
        "Replace this text with your 3-line reflection.\n",
        "Think about what you learned from this benchmark.\n",
        "What will you remember about CSV vs Parquet?\n",
        "\"\"\".strip()\n",
        "\n",
        "print(\"Your reflection:\")\n",
        "print(reflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Results to JSON\n",
        "\n",
        "Finally, let's save everything to `results/lab01_metrics.json`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {\n",
        "    \"lab\": \"01_setup_io\",\n",
        "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
        "    \"dataset\": {\n",
        "        \"rows\": 200_000,\n",
        "        \"cols\": 4,\n",
        "    },\n",
        "    \"csv\": {\n",
        "        \"size_bytes\": csv_size,\n",
        "        \"size_mb\": round(csv_size / 1_000_000, 2),\n",
        "        \"read_times_sec\": csv_result[\"runs_sec\"],\n",
        "        \"median_read_sec\": csv_result[\"median_sec\"],\n",
        "    },\n",
        "    \"parquet\": {\n",
        "        \"size_bytes\": parquet_size,\n",
        "        \"size_mb\": round(parquet_size / 1_000_000, 2),\n",
        "        \"read_times_sec\": parquet_result[\"runs_sec\"],\n",
        "        \"median_read_sec\": parquet_result[\"median_sec\"],\n",
        "    },\n",
        "    \"comparison\": {\n",
        "        \"size_ratio\": round(size_ratio, 2),\n",
        "        \"speedup\": round(speedup, 2),\n",
        "    },\n",
        "    \"reflection\": reflection,\n",
        "}\n",
        "\n",
        "save_json(results, METRICS_PATH)\n",
        "print(f\"âœ“ Results saved to: {METRICS_PATH}\")\n",
        "print(f\"\\nPreview:\")\n",
        "print(json.dumps(results, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸŽ‰ Congratulations!\n",
        "\n",
        "You've completed Lab 01. Make sure you have:\n",
        "\n",
        "- âœ… All TODO functions implemented\n",
        "- âœ… All cells executed without errors\n",
        "- âœ… `results/lab01_metrics.json` created\n",
        "- âœ… Your reflection written\n",
        "\n",
        "**Submit these files:**\n",
        "1. `notebooks/lab01_setup_io.ipynb` (this file)\n",
        "2. `results/lab01_metrics.json`\n",
        "\n",
        "See you in Lab 02! ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“š What You Learned\n",
        "\n",
        "### Technical Skills âœ…\n",
        "- Setting up Python environment with `uv`\n",
        "- Generating synthetic data with `numpy`\n",
        "- Working with `pandas` DataFrames\n",
        "- Reading/writing CSV and Parquet files\n",
        "- Measuring performance with `time.perf_counter()`\n",
        "- Saving structured data as JSON\n",
        "\n",
        "### Concepts âœ…\n",
        "- Why Parquet is faster and smaller than CSV\n",
        "- Columnar vs row-based storage\n",
        "- Using median vs mean for benchmarking\n",
        "- Importance of reproducibility (random seeds)\n",
        "- Cross-platform path handling with `pathlib`\n",
        "\n",
        "### Best Practices âœ…\n",
        "- Writing clear docstrings\n",
        "- Testing code incrementally\n",
        "- Using type hints\n",
        "- Debugging with print statements\n",
        "- Reading error messages carefully\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš€ Next Steps\n",
        "\n",
        "1. âœ… Verify all test cells passed\n",
        "2. âœ… Check `results/lab01_metrics.json` exists and looks correct\n",
        "3. âœ… Review your reflection - is it thoughtful?\n",
        "4. âœ… Submit both files (notebook + JSON)\n",
        "\n",
        "**Great job completing Lab 01!** You're ready for Lab 02! ðŸŽ‰\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
