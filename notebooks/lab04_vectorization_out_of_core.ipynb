{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Lab 04: Vectorization and Out-of-Core Computing\n",
        "\n",
        "**Course:** Big Data\n",
        "\n",
        "---\n",
        "\n",
        "## \ud83d\udc64 Student Information\n",
        "\n",
        "**Name:** `Your Name Here`\n",
        "\n",
        "**Date:** `DD/MM/YYYY`\n",
        "\n",
        "---\n",
        "\n",
        "**Goal:** Master vectorization techniques and out-of-core computing to process data efficiently at scale.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this lab, you will be able to:\n",
        "\n",
        "1. **Vectorize Operations**: Replace slow Python loops with NumPy/Pandas operations (100-200x speedup)\n",
        "2. **Use Broadcasting**: Apply operations across arrays of different shapes\n",
        "3. **Process Large Files**: Handle datasets larger than RAM using chunking\n",
        "4. **Implement Online Algorithms**: Calculate statistics with O(1) memory\n",
        "5. **Use Dask**: Scale Pandas operations to larger-than-memory datasets\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. **Fill in your information above** before starting the lab\n",
        "2. Read each cell carefully before running it\n",
        "3. Implement the **TODO functions** when you see them\n",
        "4. Run cells **from top to bottom** (Shift+Enter)\n",
        "5. Check that output makes sense after each cell\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {},
      "source": [
        "## \ud83d\udcda Libraries Used in This Lab\n",
        "\n",
        "### Core Libraries\n",
        "\n",
        "- **`numpy`** - Vectorized numerical operations\n",
        "- **`pandas`** - DataFrame operations and I/O\n",
        "- **`psutil`** - Memory monitoring\n",
        "- **`time`** - Performance measurement\n",
        "- **`dask`** (optional) - Parallel and out-of-core computing\n",
        "\n",
        "### Why Vectorization Matters\n",
        "\n",
        "Each Python loop iteration involves ~200 CPU instructions:\n",
        "- Interpret bytecode\n",
        "- Look up variables in hash table\n",
        "- Check types (dynamic typing)\n",
        "- Find methods\n",
        "- Create stack frames\n",
        "\n",
        "**NumPy**: 1-2 CPU instructions (compiled C code)\n",
        "\n",
        "**Result**: 100-200x speedup!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## 1. Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import psutil\n",
        "\n",
        "# Optional: Dask\n",
        "try:\n",
        "    import dask.dataframe as dd\n",
        "    DASK_AVAILABLE = True\n",
        "    print(f\"Dask version: {dd.__version__}\")\n",
        "except ImportError:\n",
        "    DASK_AVAILABLE = False\n",
        "    print(\"Dask not installed. Bonus exercise will be skipped.\")\n",
        "\n",
        "print(\"\\n\u2713 Core imports successful!\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-4",
      "metadata": {},
      "source": [
        "## 2. Define Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base directories\n",
        "DATA_RAW = Path(\"../data/raw\")\n",
        "DATA_PROCESSED = Path(\"../data/processed\")\n",
        "RESULTS_DIR = Path(\"../results\")\n",
        "\n",
        "# File paths for this lab\n",
        "TEST_CSV = DATA_RAW / \"benchmark_10m.csv\"\n",
        "LARGE_CSV = DATA_RAW / \"benchmark_large.csv\"\n",
        "FILTERED_OUTPUT = DATA_PROCESSED / \"filtered_output.parquet\"\n",
        "METRICS_PATH = RESULTS_DIR / \"lab04_metrics.json\"\n",
        "\n",
        "# Ensure directories exist\n",
        "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
        "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Paths defined:\")\n",
        "print(f\"  Test CSV: {TEST_CSV}\")\n",
        "print(f\"  Large CSV: {LARGE_CSV}\")\n",
        "print(f\"  Metrics: {METRICS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Dataset Generation\n",
        "\n",
        "We'll create test datasets for benchmarking:\n",
        "- **Medium dataset** (10M rows) for vectorization benchmarks\n",
        "- **Large dataset** (50M+ rows) for out-of-core exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "### TODO 1: `generate_test_data()`\n",
        "\n",
        "Generate a synthetic dataset for benchmarking.\n",
        "\n",
        "**\ud83d\udca1 Hints:**\n",
        "- Use `np.random.seed(seed)` for reproducibility\n",
        "- Use `np.random.randn()` for float columns (normal distribution)\n",
        "- Use `np.random.randint()` for integer columns\n",
        "- Use `np.random.choice()` for category column\n",
        "- Use `np.random.uniform()` for value column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_test_data(path: Path, n_rows: int = 10_000_000, seed: int = 42) -> dict:\n",
        "    \"\"\"\n",
        "    Generate a test dataset for benchmarking.\n",
        "    \n",
        "    Args:\n",
        "        path: Where to save the CSV\n",
        "        n_rows: Number of rows\n",
        "        seed: Random seed\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with metadata: {\"rows\": int, \"cols\": int, \"size_mb\": float}\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Step 1: Set random seed\n",
        "    # Step 2: Generate columns:\n",
        "    #   - 'a': random normal values (randn)\n",
        "    #   - 'b': random normal values (randn)\n",
        "    #   - 'c': random integers 0-100\n",
        "    #   - 'age': random integers 0-100\n",
        "    #   - 'category': random choice from ['A', 'B', 'C', 'D']\n",
        "    #   - 'value': random uniform 0-1000\n",
        "    # Step 3: Create DataFrame\n",
        "    # Step 4: Save to CSV\n",
        "    # Step 5: Return metadata\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate the test dataset\n",
        "if not TEST_CSV.exists():\n",
        "    print(\"Generating 10 million row test dataset...\")\n",
        "    print(\"(This may take 1-2 minutes)\\n\")\n",
        "    \n",
        "    start = time.perf_counter()\n",
        "    metadata = generate_test_data(TEST_CSV, n_rows=10_000_000)\n",
        "    elapsed = time.perf_counter() - start\n",
        "    \n",
        "    print(f\"Generated in {elapsed:.1f} seconds\")\n",
        "    print(f\"Rows: {metadata['rows']:,}\")\n",
        "    print(f\"Size: {metadata['size_mb']:.1f} MB\")\n",
        "else:\n",
        "    size_mb = TEST_CSV.stat().st_size / 1e6\n",
        "    print(f\"Dataset already exists: {size_mb:.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 1: Loop to Vectorized Conversion \ud83c\udfaf\n",
        "\n",
        "In this exercise, you'll convert slow loop-based code to fast vectorized operations.\n",
        "\n",
        "### The Problem with Python Loops\n",
        "\n",
        "```python\n",
        "# Each iteration:\n",
        "# 1. Interpret bytecode (Python VM)        ~50 instructions\n",
        "# 2. Look up variable in hash table        ~20 instructions\n",
        "# 3. Check type (dynamic typing)           ~30 instructions\n",
        "# 4. Find method (__mul__, __add__)        ~40 instructions\n",
        "# 5. Create stack frame                    ~30 instructions\n",
        "# 6. Perform actual operation              ~2 instructions\n",
        "# 7. Check result type                     ~20 instructions\n",
        "# 8. Assign result                         ~10 instructions\n",
        "# Total: ~200 CPU instructions per operation!\n",
        "```\n",
        "\n",
        "**NumPy**: Direct CPU operations in compiled C code = 1-2 instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a sample of the data for testing\n",
        "print(\"Loading sample data for vectorization exercises...\")\n",
        "df_sample = pd.read_csv(TEST_CSV, nrows=100_000)\n",
        "print(f\"Sample size: {len(df_sample):,} rows\")\n",
        "print(f\"\\nColumns: {list(df_sample.columns)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-12",
      "metadata": {},
      "source": [
        "### Part 1A: Distance Calculation\n",
        "\n",
        "Convert a loop-based Euclidean distance calculation to NumPy broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original slow implementation\n",
        "def calculate_distances_slow(points_a, points_b):\n",
        "    \"\"\"Calculate Euclidean distances using a loop.\"\"\"\n",
        "    distances = []\n",
        "    for i in range(len(points_a)):\n",
        "        dist = math.sqrt(\n",
        "            (points_a[i][0] - points_b[i][0])**2 +\n",
        "            (points_a[i][1] - points_b[i][1])**2\n",
        "        )\n",
        "        distances.append(dist)\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-14",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_distances_fast(points_a: np.ndarray, points_b: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calculate Euclidean distances using vectorization.\n",
        "    \n",
        "    Args:\n",
        "        points_a: Array of shape (N, 2) with x, y coordinates\n",
        "        points_b: Array of shape (N, 2) with x, y coordinates\n",
        "    \n",
        "    Returns:\n",
        "        Array of distances\n",
        "    \n",
        "    Hints:\n",
        "        - Use broadcasting: diff = points_a - points_b\n",
        "        - Square: diff**2\n",
        "        - Sum along axis 1: np.sum(..., axis=1)\n",
        "        - Square root: np.sqrt(...)\n",
        "        - Or use np.linalg.norm(points_a - points_b, axis=1)\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test distance calculation\n",
        "n_points = 100_000\n",
        "np.random.seed(42)\n",
        "points_a = np.random.randn(n_points, 2)\n",
        "points_b = np.random.randn(n_points, 2)\n",
        "\n",
        "# Benchmark slow version\n",
        "start = time.perf_counter()\n",
        "result_slow = calculate_distances_slow(points_a, points_b)\n",
        "time_slow = time.perf_counter() - start\n",
        "\n",
        "# Benchmark fast version\n",
        "start = time.perf_counter()\n",
        "result_fast = calculate_distances_fast(points_a, points_b)\n",
        "time_fast = time.perf_counter() - start\n",
        "\n",
        "# Verify results match\n",
        "if result_fast is not None:\n",
        "    match = np.allclose(result_slow, result_fast)\n",
        "    speedup = time_slow / time_fast\n",
        "    print(f\"Distance calculation ({n_points:,} points):\")\n",
        "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
        "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
        "    print(f\"  Speedup: {speedup:.1f}x\")\n",
        "    print(f\"  Results match: {match}\")\n",
        "else:\n",
        "    print(\"TODO: Implement calculate_distances_fast()\")\n",
        "    speedup = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "### Part 1B: Age Classification\n",
        "\n",
        "Replace conditional loop with `np.select()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original slow implementation\n",
        "def classify_ages_slow(ages):\n",
        "    \"\"\"Classify ages using a loop.\"\"\"\n",
        "    categories = []\n",
        "    for age in ages:\n",
        "        if age < 18:\n",
        "            categories.append('child')\n",
        "        elif age < 65:\n",
        "            categories.append('adult')\n",
        "        else:\n",
        "            categories.append('senior')\n",
        "    return categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_ages_fast(ages: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Classify ages using vectorization.\n",
        "    \n",
        "    Args:\n",
        "        ages: Array of ages\n",
        "    \n",
        "    Returns:\n",
        "        Array of categories ('child', 'adult', 'senior')\n",
        "    \n",
        "    Hints:\n",
        "        - Use np.select(conditions, choices)\n",
        "        - conditions = [ages < 18, ages < 65, ages >= 65]\n",
        "        - choices = ['child', 'adult', 'senior']\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test age classification\n",
        "ages = df_sample['age'].values\n",
        "\n",
        "# Benchmark\n",
        "start = time.perf_counter()\n",
        "result_slow = classify_ages_slow(ages)\n",
        "time_slow = time.perf_counter() - start\n",
        "\n",
        "start = time.perf_counter()\n",
        "result_fast = classify_ages_fast(ages)\n",
        "time_fast = time.perf_counter() - start\n",
        "\n",
        "if result_fast is not None:\n",
        "    match = all(s == f for s, f in zip(result_slow, result_fast))\n",
        "    speedup_ages = time_slow / time_fast\n",
        "    print(f\"Age classification ({len(ages):,} values):\")\n",
        "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
        "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
        "    print(f\"  Speedup: {speedup_ages:.1f}x\")\n",
        "    print(f\"  Results match: {match}\")\n",
        "else:\n",
        "    print(\"TODO: Implement classify_ages_fast()\")\n",
        "    speedup_ages = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-20",
      "metadata": {},
      "source": [
        "### Part 1C: Column Normalization\n",
        "\n",
        "Replace nested loops with broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original slow implementation\n",
        "def normalize_columns_slow(df, columns):\n",
        "    \"\"\"Normalize columns using nested loops.\"\"\"\n",
        "    df = df.copy()\n",
        "    for col in columns:\n",
        "        values = df[col].values\n",
        "        mean = sum(values) / len(values)\n",
        "        variance = sum((x - mean)**2 for x in values) / len(values)\n",
        "        std = math.sqrt(variance)\n",
        "        for i in range(len(df)):\n",
        "            df.loc[i, col] = (df.loc[i, col] - mean) / std\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_columns_fast(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Normalize columns using vectorization.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame to normalize\n",
        "        columns: List of columns to normalize\n",
        "    \n",
        "    Returns:\n",
        "        Normalized DataFrame\n",
        "    \n",
        "    Hints:\n",
        "        - Use df[columns].mean() to get means for all columns at once\n",
        "        - Use df[columns].std() for standard deviations\n",
        "        - Broadcasting: (df[columns] - mean) / std\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test normalization (use smaller sample due to slow version)\n",
        "df_norm_test = df_sample.head(10_000).copy()\n",
        "columns_to_normalize = ['a', 'b', 'value']\n",
        "\n",
        "# Benchmark\n",
        "start = time.perf_counter()\n",
        "result_slow = normalize_columns_slow(df_norm_test, columns_to_normalize)\n",
        "time_slow = time.perf_counter() - start\n",
        "\n",
        "start = time.perf_counter()\n",
        "result_fast = normalize_columns_fast(df_norm_test, columns_to_normalize)\n",
        "time_fast = time.perf_counter() - start\n",
        "\n",
        "if result_fast is not None:\n",
        "    match = np.allclose(result_slow[columns_to_normalize].values, \n",
        "                        result_fast[columns_to_normalize].values, rtol=1e-5)\n",
        "    speedup_norm = time_slow / time_fast\n",
        "    print(f\"Normalization ({len(df_norm_test):,} rows, {len(columns_to_normalize)} columns):\")\n",
        "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
        "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
        "    print(f\"  Speedup: {speedup_norm:.1f}x\")\n",
        "    print(f\"  Results match: {match}\")\n",
        "else:\n",
        "    print(\"TODO: Implement normalize_columns_fast()\")\n",
        "    speedup_norm = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-24",
      "metadata": {},
      "source": [
        "### Part 1D: Score Calculation with Clipping\n",
        "\n",
        "Replace loop with vectorized operations and `np.clip()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-25",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Original slow implementation\n",
        "def calculate_scores_slow(df):\n",
        "    \"\"\"Calculate scores using a loop.\"\"\"\n",
        "    scores = []\n",
        "    for i in range(len(df)):\n",
        "        row = df.iloc[i]\n",
        "        score = (row['a'] * 2 + row['b']) / (row['c'] + 1)\n",
        "        if score > 10:\n",
        "            score = 10\n",
        "        elif score < -10:\n",
        "            score = -10\n",
        "        scores.append(score)\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-26",
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_scores_fast(df: pd.DataFrame) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calculate scores using vectorization.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with columns 'a', 'b', 'c'\n",
        "    \n",
        "    Returns:\n",
        "        Array of scores (clipped to [-10, 10])\n",
        "    \n",
        "    Hints:\n",
        "        - Vectorized formula: (df['a'] * 2 + df['b']) / (df['c'] + 1)\n",
        "        - Use np.clip(scores, -10, 10) to clip values\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test score calculation\n",
        "df_score_test = df_sample.head(50_000).copy()\n",
        "\n",
        "# Benchmark\n",
        "start = time.perf_counter()\n",
        "result_slow = calculate_scores_slow(df_score_test)\n",
        "time_slow = time.perf_counter() - start\n",
        "\n",
        "start = time.perf_counter()\n",
        "result_fast = calculate_scores_fast(df_score_test)\n",
        "time_fast = time.perf_counter() - start\n",
        "\n",
        "if result_fast is not None:\n",
        "    match = np.allclose(result_slow, result_fast)\n",
        "    speedup_scores = time_slow / time_fast\n",
        "    print(f\"Score calculation ({len(df_score_test):,} rows):\")\n",
        "    print(f\"  Slow: {time_slow:.4f} sec\")\n",
        "    print(f\"  Fast: {time_fast:.6f} sec\")\n",
        "    print(f\"  Speedup: {speedup_scores:.1f}x\")\n",
        "    print(f\"  Results match: {match}\")\n",
        "else:\n",
        "    print(\"TODO: Implement calculate_scores_fast()\")\n",
        "    speedup_scores = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-28",
      "metadata": {},
      "source": [
        "### \ud83d\udca1 Key Insight: The .apply() Trap\n",
        "\n",
        "`.apply()` looks clean but is NOT vectorized:\n",
        "\n",
        "```python\n",
        "# This is SLOW (hidden Python loop):\n",
        "df['result'] = df['x'].apply(lambda x: x * 2)\n",
        "\n",
        "# This is FAST (vectorized):\n",
        "df['result'] = df['x'] * 2\n",
        "```\n",
        "\n",
        "**Benchmark on 10M elements:**\n",
        "| Method | Time | Speedup |\n",
        "|--------|------|---------|\n",
        "| Python loop | 12.5s | 1x |\n",
        "| `.apply()` | 5.8s | 2.2x |\n",
        "| Vectorized | 0.062s | **200x** |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-29",
      "metadata": {},
      "source": [
        "## Exercise 2: Benchmarking \ud83d\udcca\n",
        "\n",
        "Quantify the performance impact of vectorization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-30",
      "metadata": {},
      "outputs": [],
      "source": [
        "def benchmark_operation(slow_fn, fast_fn, *args, n_runs: int = 3) -> dict:\n",
        "    \"\"\"\n",
        "    Benchmark slow vs fast function.\n",
        "    \n",
        "    Args:\n",
        "        slow_fn: Slow function\n",
        "        fast_fn: Fast function  \n",
        "        *args: Arguments to pass to functions\n",
        "        n_runs: Number of runs for timing\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with timing results\n",
        "    \"\"\"\n",
        "    # Time slow function\n",
        "    slow_times = []\n",
        "    for _ in range(n_runs):\n",
        "        start = time.perf_counter()\n",
        "        slow_result = slow_fn(*args)\n",
        "        slow_times.append(time.perf_counter() - start)\n",
        "    \n",
        "    # Time fast function\n",
        "    fast_times = []\n",
        "    for _ in range(n_runs):\n",
        "        start = time.perf_counter()\n",
        "        fast_result = fast_fn(*args)\n",
        "        fast_times.append(time.perf_counter() - start)\n",
        "    \n",
        "    slow_median = np.median(slow_times)\n",
        "    fast_median = np.median(fast_times)\n",
        "    \n",
        "    return {\n",
        "        'slow_sec': round(slow_median, 4),\n",
        "        'fast_sec': round(fast_median, 6),\n",
        "        'speedup': round(slow_median / fast_median, 1) if fast_median > 0 else float('inf')\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-31",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run comprehensive benchmarks\n",
        "print(\"Running comprehensive benchmarks...\\n\")\n",
        "\n",
        "benchmark_results = {}\n",
        "\n",
        "# 1. Distance calculation\n",
        "if 'result_fast' in dir() and result_fast is not None:\n",
        "    n = 50_000\n",
        "    pts_a = np.random.randn(n, 2)\n",
        "    pts_b = np.random.randn(n, 2)\n",
        "    benchmark_results['distance'] = benchmark_operation(\n",
        "        calculate_distances_slow, calculate_distances_fast, pts_a, pts_b\n",
        "    )\n",
        "    print(f\"Distance: {benchmark_results['distance']['speedup']}x speedup\")\n",
        "\n",
        "# 2. Age classification\n",
        "if 'speedup_ages' in dir() and speedup_ages is not None:\n",
        "    ages_test = np.random.randint(0, 100, 100_000)\n",
        "    benchmark_results['age_classification'] = benchmark_operation(\n",
        "        classify_ages_slow, classify_ages_fast, ages_test\n",
        "    )\n",
        "    print(f\"Age classification: {benchmark_results['age_classification']['speedup']}x speedup\")\n",
        "\n",
        "# 3. Score calculation\n",
        "if 'speedup_scores' in dir() and speedup_scores is not None:\n",
        "    df_bench = df_sample.head(20_000).copy()\n",
        "    benchmark_results['scores'] = benchmark_operation(\n",
        "        calculate_scores_slow, calculate_scores_fast, df_bench\n",
        "    )\n",
        "    print(f\"Score calculation: {benchmark_results['scores']['speedup']}x speedup\")\n",
        "\n",
        "print(\"\\n\u2713 Benchmarks complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-32",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3: Out-of-Core Processing \ud83d\udcbe\n",
        "\n",
        "Process datasets larger than RAM using chunking.\n",
        "\n",
        "### The Problem\n",
        "\n",
        "```python\n",
        "# This FAILS with MemoryError for large files:\n",
        "df = pd.read_csv('huge_file.csv')  # Tries to load all into RAM\n",
        "result = df['value'].mean()\n",
        "```\n",
        "\n",
        "### The Solution: Chunking\n",
        "\n",
        "```python\n",
        "# Process in chunks:\n",
        "for chunk in pd.read_csv('huge_file.csv', chunksize=500_000):\n",
        "    # Process each chunk\n",
        "    partial_result = process(chunk)\n",
        "    # Combine results\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-33",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: Get current memory usage\n",
        "def get_memory_mb() -> float:\n",
        "    \"\"\"Get current process memory in MB.\"\"\"\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return process.memory_info().rss / 1024 / 1024\n",
        "\n",
        "print(f\"Current memory usage: {get_memory_mb():.1f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-34",
      "metadata": {},
      "source": [
        "### Part 3A: Chunked Mean Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-35",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunked_mean(path: Path, column: str, chunksize: int = 500_000) -> dict:\n",
        "    \"\"\"\n",
        "    Calculate mean using chunking.\n",
        "    \n",
        "    Args:\n",
        "        path: Path to CSV file\n",
        "        column: Column to calculate mean for\n",
        "        chunksize: Rows per chunk\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with mean and memory stats\n",
        "    \n",
        "    Hints:\n",
        "        - Keep running total_sum and total_count\n",
        "        - For each chunk: total_sum += chunk[column].sum()\n",
        "        - For each chunk: total_count += len(chunk)\n",
        "        - Track peak memory with get_memory_mb()\n",
        "        - Final mean = total_sum / total_count\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-36",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test chunked mean vs full load\n",
        "print(\"Comparing chunked vs full load...\\n\")\n",
        "\n",
        "# Full load\n",
        "mem_before = get_memory_mb()\n",
        "start = time.perf_counter()\n",
        "df_full = pd.read_csv(TEST_CSV)\n",
        "full_mean = df_full['value'].mean()\n",
        "full_time = time.perf_counter() - start\n",
        "full_memory = get_memory_mb() - mem_before\n",
        "del df_full  # Free memory\n",
        "\n",
        "print(f\"Full load:\")\n",
        "print(f\"  Mean: {full_mean:.6f}\")\n",
        "print(f\"  Time: {full_time:.2f} sec\")\n",
        "print(f\"  Memory: {full_memory:.1f} MB\")\n",
        "\n",
        "# Chunked\n",
        "chunked_result = chunked_mean(TEST_CSV, 'value')\n",
        "if chunked_result:\n",
        "    print(f\"\\nChunked:\")\n",
        "    print(f\"  Mean: {chunked_result['mean']:.6f}\")\n",
        "    print(f\"  Count: {chunked_result['count']:,}\")\n",
        "    print(f\"  Peak memory: {chunked_result['peak_memory_mb']:.1f} MB\")\n",
        "    print(f\"\\nMeans match: {abs(full_mean - chunked_result['mean']) < 1e-10}\")\n",
        "else:\n",
        "    print(\"\\nTODO: Implement chunked_mean()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-37",
      "metadata": {},
      "source": [
        "### Part 3B: Chunked Filter and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-38",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunked_filter(input_path: Path, output_path: Path,\n",
        "                   column: str, value: str, chunksize: int = 500_000) -> dict:\n",
        "    \"\"\"\n",
        "    Filter large file and save subset using chunking.\n",
        "    \n",
        "    Args:\n",
        "        input_path: Input CSV path\n",
        "        output_path: Output Parquet path\n",
        "        column: Column to filter on\n",
        "        value: Value to filter for\n",
        "        chunksize: Rows per chunk\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with stats\n",
        "    \n",
        "    Hints:\n",
        "        - Filter each chunk: filtered = chunk[chunk[column] == value]\n",
        "        - For first chunk with data: filtered.to_parquet(output_path)\n",
        "        - For subsequent chunks: append using pd.concat\n",
        "        - Track input and output row counts\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-39",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test chunked filter\n",
        "print(\"Filtering category='A' from dataset...\\n\")\n",
        "\n",
        "filter_result = chunked_filter(TEST_CSV, FILTERED_OUTPUT, 'category', 'A')\n",
        "if filter_result:\n",
        "    print(f\"Input rows: {filter_result['input_rows']:,}\")\n",
        "    print(f\"Output rows: {filter_result['output_rows']:,}\")\n",
        "    print(f\"Ratio: {filter_result['ratio']:.2%}\")\n",
        "    \n",
        "    # Verify output\n",
        "    if FILTERED_OUTPUT.exists():\n",
        "        df_check = pd.read_parquet(FILTERED_OUTPUT)\n",
        "        print(f\"\\nVerification: {len(df_check):,} rows in output file\")\n",
        "        print(f\"All category='A': {(df_check['category'] == 'A').all()}\")\n",
        "else:\n",
        "    print(\"TODO: Implement chunked_filter()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-40",
      "metadata": {},
      "source": [
        "### Part 3C: Chunked GroupBy Aggregation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-41",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chunked_groupby_sum(path: Path, group_col: str,\n",
        "                        agg_col: str, chunksize: int = 500_000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Perform groupby sum using chunking.\n",
        "    \n",
        "    Args:\n",
        "        path: Path to CSV file\n",
        "        group_col: Column to group by\n",
        "        agg_col: Column to sum\n",
        "        chunksize: Rows per chunk\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with aggregated results (sum, count, mean per group)\n",
        "    \n",
        "    Hints:\n",
        "        - Use defaultdict(float) for group_sums\n",
        "        - Use defaultdict(int) for group_counts\n",
        "        - For each chunk: aggregate with chunk.groupby(group_col)[agg_col].agg(['sum', 'count'])\n",
        "        - Accumulate into global totals\n",
        "        - Calculate mean = sum / count at the end\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test chunked groupby\n",
        "print(\"Calculating sum by category...\\n\")\n",
        "\n",
        "groupby_result = chunked_groupby_sum(TEST_CSV, 'category', 'value')\n",
        "if groupby_result is not None:\n",
        "    print(\"Chunked groupby result:\")\n",
        "    print(groupby_result)\n",
        "    \n",
        "    # Verify against full load\n",
        "    df_verify = pd.read_csv(TEST_CSV)\n",
        "    full_result = df_verify.groupby('category')['value'].agg(['sum', 'count', 'mean'])\n",
        "    print(\"\\nFull load result:\")\n",
        "    print(full_result)\n",
        "    del df_verify\n",
        "else:\n",
        "    print(\"TODO: Implement chunked_groupby_sum()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-43",
      "metadata": {},
      "source": [
        "### \ud83d\udca1 Key Insight: Chunking Compatibility\n",
        "\n",
        "| Operation | Compatible | Strategy |\n",
        "|-----------|------------|----------|\n",
        "| Sum | \u2705 Yes | Accumulate partial sums |\n",
        "| Mean | \u2705 Yes | Sum / Count |\n",
        "| Min/Max | \u2705 Yes | Running min/max |\n",
        "| Variance | \u2705 Yes | Welford's algorithm |\n",
        "| Groupby | \u2705 Yes | Accumulate per group |\n",
        "| Filter | \u2705 Yes | Write matching rows |\n",
        "| Sort | \u274c No | External merge sort |\n",
        "| Median | \u274c No | Approximate algorithms |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-44",
      "metadata": {},
      "source": [
        "## Exercise 4: Online Statistics (Welford's Algorithm) \ud83d\udcca\n",
        "\n",
        "Calculate statistics in a single pass with O(1) memory.\n",
        "\n",
        "### The Problem with Standard Formulas\n",
        "\n",
        "```python\n",
        "# Naive variance (requires TWO passes and ALL data in memory):\n",
        "mean = sum(data) / len(data)  # Pass 1\n",
        "variance = sum((x - mean)**2 for x in data) / len(data)  # Pass 2\n",
        "```\n",
        "\n",
        "### Welford's Algorithm (One Pass)\n",
        "\n",
        "- **Memory**: O(1) - only 3 variables\n",
        "- **Passes**: 1 - single scan\n",
        "- **Numerically stable**: Avoids catastrophic cancellation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-45",
      "metadata": {},
      "outputs": [],
      "source": [
        "class OnlineStats:\n",
        "    \"\"\"\n",
        "    Calculate running statistics using Welford's algorithm.\n",
        "    \n",
        "    Properties:\n",
        "        - O(1) memory\n",
        "        - Single pass\n",
        "        - Numerically stable\n",
        "    \n",
        "    Welford's update formulas:\n",
        "        count += 1\n",
        "        delta = x - mean\n",
        "        mean += delta / count\n",
        "        delta2 = x - mean  # Using NEW mean\n",
        "        M2 += delta * delta2\n",
        "    \n",
        "    Variance = M2 / count\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.mean = 0.0\n",
        "        self.M2 = 0.0  # Sum of squared differences from mean\n",
        "        self.min_val = float('inf')\n",
        "        self.max_val = float('-inf')\n",
        "    \n",
        "    def update(self, x: float) -> None:\n",
        "        \"\"\"\n",
        "        Update statistics with a new value.\n",
        "        \n",
        "        TODO: Implement Welford's algorithm\n",
        "        \n",
        "        Steps:\n",
        "        1. Increment count\n",
        "        2. Calculate delta = x - mean\n",
        "        3. Update mean: mean += delta / count\n",
        "        4. Calculate delta2 = x - mean (using UPDATED mean)\n",
        "        5. Update M2: M2 += delta * delta2\n",
        "        6. Update min/max\n",
        "        \"\"\"\n",
        "        # TODO: Implement this method\n",
        "        pass\n",
        "    \n",
        "    def update_batch(self, values: np.ndarray) -> None:\n",
        "        \"\"\"Update with multiple values.\"\"\"\n",
        "        for x in values:\n",
        "            self.update(x)\n",
        "    \n",
        "    def variance(self) -> float:\n",
        "        \"\"\"Return population variance.\"\"\"\n",
        "        if self.count < 2:\n",
        "            return 0.0\n",
        "        return self.M2 / self.count\n",
        "    \n",
        "    def std(self) -> float:\n",
        "        \"\"\"Return population standard deviation.\"\"\"\n",
        "        return np.sqrt(self.variance())\n",
        "    \n",
        "    def summary(self) -> dict:\n",
        "        \"\"\"Return summary of all statistics.\"\"\"\n",
        "        return {\n",
        "            'count': self.count,\n",
        "            'mean': self.mean,\n",
        "            'std': self.std(),\n",
        "            'min': self.min_val,\n",
        "            'max': self.max_val\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-46",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test OnlineStats\n",
        "print(\"Testing OnlineStats (Welford's algorithm)...\\n\")\n",
        "\n",
        "# Generate test data\n",
        "np.random.seed(42)\n",
        "test_data = np.random.randn(1_000_000)\n",
        "\n",
        "# Calculate with OnlineStats\n",
        "stats = OnlineStats()\n",
        "stats.update_batch(test_data)\n",
        "online_result = stats.summary()\n",
        "\n",
        "# Calculate with NumPy (ground truth)\n",
        "numpy_result = {\n",
        "    'count': len(test_data),\n",
        "    'mean': np.mean(test_data),\n",
        "    'std': np.std(test_data),\n",
        "    'min': np.min(test_data),\n",
        "    'max': np.max(test_data)\n",
        "}\n",
        "\n",
        "if online_result['count'] > 0:\n",
        "    print(\"Comparison:\")\n",
        "    print(f\"{'Metric':<10} {'OnlineStats':<15} {'NumPy':<15} {'Match'}\")\n",
        "    print(\"-\" * 50)\n",
        "    for key in ['count', 'mean', 'std', 'min', 'max']:\n",
        "        online_val = online_result[key]\n",
        "        numpy_val = numpy_result[key]\n",
        "        if isinstance(online_val, float):\n",
        "            match = abs(online_val - numpy_val) < 1e-10\n",
        "            print(f\"{key:<10} {online_val:<15.6f} {numpy_val:<15.6f} {\"\u2713\" if match else \"\u2717\"}\")\n",
        "        else:\n",
        "            match = online_val == numpy_val\n",
        "            print(f\"{key:<10} {online_val:<15,} {numpy_val:<15,} {\"\u2713\" if match else \"\u2717\"}\")\n",
        "else:\n",
        "    print(\"TODO: Implement OnlineStats.update()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-47",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply OnlineStats to large file with chunking\n",
        "print(\"Calculating statistics on large file with chunking + OnlineStats...\\n\")\n",
        "\n",
        "stats_chunked = OnlineStats()\n",
        "chunks_processed = 0\n",
        "\n",
        "start = time.perf_counter()\n",
        "for chunk in pd.read_csv(TEST_CSV, chunksize=500_000, usecols=['value']):\n",
        "    stats_chunked.update_batch(chunk['value'].values)\n",
        "    chunks_processed += 1\n",
        "elapsed = time.perf_counter() - start\n",
        "\n",
        "if stats_chunked.count > 0:\n",
        "    result = stats_chunked.summary()\n",
        "    print(f\"Processed {chunks_processed} chunks in {elapsed:.2f} sec\")\n",
        "    print(f\"\\nResults:\")\n",
        "    print(f\"  Count: {result['count']:,}\")\n",
        "    print(f\"  Mean: {result['mean']:.6f}\")\n",
        "    print(f\"  Std: {result['std']:.6f}\")\n",
        "    print(f\"  Min: {result['min']:.6f}\")\n",
        "    print(f\"  Max: {result['max']:.6f}\")\n",
        "else:\n",
        "    print(\"TODO: Implement OnlineStats.update()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-48",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 5 (Bonus): Introduction to Dask \ud83d\ude80\n",
        "\n",
        "Compare Dask with manual chunking.\n",
        "\n",
        "**Dask** = \"Pandas but bigger\"\n",
        "- Lazy evaluation\n",
        "- Automatic parallelism\n",
        "- Familiar API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-49",
      "metadata": {},
      "outputs": [],
      "source": [
        "if DASK_AVAILABLE:\n",
        "    print(\"Dask is available! Running bonus exercise...\\n\")\n",
        "    \n",
        "    # Read with Dask (lazy - no data loaded yet)\n",
        "    print(\"Creating Dask DataFrame (lazy)...\")\n",
        "    ddf = dd.read_csv(TEST_CSV)\n",
        "    print(f\"Type: {type(ddf)}\")\n",
        "    print(f\"Partitions: {ddf.npartitions}\")\n",
        "    print(f\"\\nNote: No data has been loaded yet!\")\n",
        "else:\n",
        "    print(\"Dask not installed. Skipping bonus exercise.\")\n",
        "    print(\"To install: pip install 'dask[complete]'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-50",
      "metadata": {},
      "outputs": [],
      "source": [
        "if DASK_AVAILABLE:\n",
        "    # Compare Dask vs manual chunking for groupby\n",
        "    print(\"Comparing Dask vs manual chunking for groupby...\\n\")\n",
        "    \n",
        "    # Manual chunking\n",
        "    start = time.perf_counter()\n",
        "    manual_result = chunked_groupby_sum(TEST_CSV, 'category', 'value')\n",
        "    manual_time = time.perf_counter() - start\n",
        "    \n",
        "    # Dask\n",
        "    start = time.perf_counter()\n",
        "    dask_result = ddf.groupby('category')['value'].sum().compute()\n",
        "    dask_time = time.perf_counter() - start\n",
        "    \n",
        "    print(f\"Manual chunking: {manual_time:.3f} sec\")\n",
        "    print(f\"Dask: {dask_time:.3f} sec\")\n",
        "    print(f\"\\nDask speedup: {manual_time / dask_time:.2f}x\")\n",
        "    \n",
        "    # Verify results match\n",
        "    if manual_result is not None:\n",
        "        manual_sums = manual_result['sum'].sort_index()\n",
        "        dask_sums = dask_result.sort_index()\n",
        "        match = np.allclose(manual_sums.values, dask_sums.values, rtol=1e-5)\n",
        "        print(f\"Results match: {match}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-51",
      "metadata": {},
      "outputs": [],
      "source": [
        "if DASK_AVAILABLE:\n",
        "    # Show Dask's lazy evaluation\n",
        "    print(\"Dask's lazy evaluation:\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    # Define computation (nothing runs yet)\n",
        "    lazy_result = ddf.groupby('category')['value'].mean()\n",
        "    print(f\"Lazy result type: {type(lazy_result)}\")\n",
        "    print(f\"\\nPrint lazy result (shows task graph, not data):\")\n",
        "    print(lazy_result)\n",
        "    \n",
        "    # Execute computation\n",
        "    print(f\"\\nAfter .compute() (actually runs):\")\n",
        "    actual_result = lazy_result.compute()\n",
        "    print(actual_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-52",
      "metadata": {},
      "source": [
        "### \ud83d\udca1 When to Use What\n",
        "\n",
        "| Tool | Data Size | Use Case |\n",
        "|------|-----------|----------|\n",
        "| Pandas | < 1 GB | Standard analysis |\n",
        "| Manual Chunking | 1-10 GB | Simple aggregations, full control |\n",
        "| Dask | 1-100 GB | Complex operations, automatic parallelism |\n",
        "| Spark | > 100 GB | Multi-node cluster, distributed computing |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-53",
      "metadata": {},
      "source": [
        "## 5. Reflection\n",
        "\n",
        "**Your task:** Write a short reflection (3-5 sentences) answering:\n",
        "\n",
        "1. What was the biggest speedup you achieved with vectorization?\n",
        "2. When would you use chunking vs loading the full dataset?\n",
        "3. How does Welford's algorithm solve the memory problem for variance calculation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-54",
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Write your reflection here\n",
        "reflection = \"\"\"\n",
        "Replace this text with your reflection.\n",
        "Think about what you learned about vectorization and out-of-core computing.\n",
        "What will you do differently in your future projects?\n",
        "\"\"\".strip()\n",
        "\n",
        "print(\"Your reflection:\")\n",
        "print(reflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-55",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 6. Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-56",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "results = {\n",
        "    \"lab\": \"04_vectorization_out_of_core\",\n",
        "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
        "    \"exercise_1_vectorization\": {\n",
        "        \"distance_speedup\": benchmark_results.get('distance', {}).get('speedup'),\n",
        "        \"age_classification_speedup\": benchmark_results.get('age_classification', {}).get('speedup'),\n",
        "        \"normalization_speedup\": speedup_norm if 'speedup_norm' in dir() else None,\n",
        "        \"scores_speedup\": benchmark_results.get('scores', {}).get('speedup'),\n",
        "    },\n",
        "    \"exercise_2_benchmarks\": benchmark_results,\n",
        "    \"exercise_3_chunking\": {\n",
        "        \"chunked_mean_result\": chunked_result if 'chunked_result' in dir() else None,\n",
        "        \"chunked_filter_result\": filter_result if 'filter_result' in dir() else None,\n",
        "    },\n",
        "    \"exercise_4_online_stats\": {\n",
        "        \"welford_result\": online_result if 'online_result' in dir() and online_result['count'] > 0 else None,\n",
        "    },\n",
        "    \"exercise_5_dask\": {\n",
        "        \"available\": DASK_AVAILABLE,\n",
        "    },\n",
        "    \"reflection\": reflection,\n",
        "}\n",
        "\n",
        "# Save to JSON\n",
        "with open(METRICS_PATH, \"w\") as f:\n",
        "    json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "print(f\"\u2713 Results saved to: {METRICS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-57",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \ud83c\udf89 Lab Complete!\n",
        "\n",
        "### What You Learned\n",
        "\n",
        "1. **Vectorization**: NumPy/Pandas operations are 100-200x faster than Python loops\n",
        "2. **Broadcasting**: Apply operations across arrays without explicit loops\n",
        "3. **The .apply() Trap**: It's a hidden loop, not vectorization\n",
        "4. **Chunking**: Process datasets larger than RAM piece by piece\n",
        "5. **Welford's Algorithm**: Calculate mean and variance in O(1) memory\n",
        "6. **Dask**: Scales Pandas with lazy evaluation and parallelism\n",
        "\n",
        "### Optimization Checklist\n",
        "\n",
        "- \u2705 Never use Python loops for array operations\n",
        "- \u2705 Replace `.apply()` with vectorized operations\n",
        "- \u2705 Use broadcasting for multi-array operations\n",
        "- \u2705 Use chunking for files larger than RAM\n",
        "- \u2705 Use online algorithms for streaming statistics\n",
        "\n",
        "### Vectorization Cheat Sheet\n",
        "\n",
        "| Pattern | Slow | Fast |\n",
        "|---------|------|------|\n",
        "| Arithmetic | loop + append | `df['a'] * df['b']` |\n",
        "| Conditional | loop + if/else | `np.where()` or `np.select()` |\n",
        "| Binning | loop + if/elif | `pd.cut()` |\n",
        "| Clipping | loop + min/max | `np.clip()` |\n",
        "| Normalization | nested loops | `(df - mean) / std` |\n",
        "| Distance | loop + math.sqrt | `np.linalg.norm()` |\n",
        "\n",
        "### Files to Submit\n",
        "\n",
        "1. `notebooks/lab04_vectorization_out_of_core.ipynb` (this notebook)\n",
        "2. `results/lab04_metrics.json`\n",
        "\n",
        "---\n",
        "\n",
        "**Next Lab**: We'll explore parallel processing and distributed computing with PySpark!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
